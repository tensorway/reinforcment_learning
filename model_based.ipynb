{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pprint import pprint\n",
    "import utils\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "envname = 'BipedalWalker-v3'\n",
    "envname = 'LunarLanderContinuous-v2'\n",
    "envname = 'Pendulum-v0'\n",
    "env = gym.make(envname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer():\n",
    "    def __init__(self, max_len=100000):\n",
    "        self.old_obs = deque([])\n",
    "        self.a = deque([])\n",
    "        self.r = deque([])\n",
    "        self.obs = deque([])\n",
    "        self.size = max_len\n",
    "        self.length = 0\n",
    "        self.max_len = max_len\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    def remover(self):\n",
    "        if self.length > self.max_len:\n",
    "            self.a.popleft()\n",
    "            self.old_obs.popleft()\n",
    "            self.r.popleft()\n",
    "            self.obs.popleft()\n",
    "            self.length -= 1\n",
    "    def add(self, old_obs, a, r, obs):\n",
    "        self.old_obs.append(old_obs)\n",
    "        self.a.append(a)\n",
    "        self.r.append(r)\n",
    "        self.obs.append(obs)\n",
    "        self.length += 1\n",
    "        self.remover()\n",
    "    def get(self, bsize):\n",
    "        lidx = random.sample(range(0, self.length), bsize)\n",
    "        old_obs = [self.old_obs[i] for i in lidx]\n",
    "        a       = [self.a[i] for i in lidx]\n",
    "        r       = [self.r[i] for i in lidx]\n",
    "        obs     = [self.obs[i] for i in lidx]\n",
    "        \n",
    "        old_obs = torch.tensor(list(old_obs), dtype=torch.float).detach()\n",
    "        a       = torch.tensor(list(a)      , dtype=torch.float).detach()\n",
    "        r       = torch.tensor(list(r)      , dtype=torch.float).detach().unsqueeze(-1)\n",
    "        obs     = torch.tensor(list(obs)    , dtype=torch.float).detach()\n",
    "        return old_obs, a, r, obs\n",
    "    \n",
    "repbuff = ReplayBuffer(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Model(\n  (lin1): Linear(in_features=4, out_features=128, bias=True)\n  (lin2): Linear(in_features=128, out_features=64, bias=True)\n  (lin3): Linear(in_features=64, out_features=1, bias=True)\n  (lin4): Linear(in_features=64, out_features=3, bias=True)\n)"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, idim, h1dim, h2dim, rdim, obsdim):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(idim, h1dim)\n",
    "        self.lin2 = nn.Linear(h1dim, h2dim)\n",
    "        self.lin3 = nn.Linear(h2dim, rdim)\n",
    "        self.lin4 = nn.Linear(h2dim, obsdim)\n",
    "    def forward(self, oldobs, a):\n",
    "        #x = torch.tensor(x, dtype=torch.float)\n",
    "        x = torch.cat((oldobs, a), dim=1)\n",
    "        h = self.lin1(x)\n",
    "        h = F.relu(h)\n",
    "        h = self.lin2(h)\n",
    "        h = F.relu(h)\n",
    "        r = self.lin3(h)\n",
    "        obs = self.lin4(h) + oldobs\n",
    "        return r, obs\n",
    "    \n",
    "adim = env.action_space.shape[0]\n",
    "sdim = env.observation_space.shape[0]\n",
    "rdim = 1\n",
    "idim = adim + sdim\n",
    "odim = rdim + sdim\n",
    "model = Model(idim, 128, 64, rdim, sdim)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr=5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "30 577.809814453125 52.528167724609375 0.07369256019592285\n40 296.0943908691406 26.917673110961914 0.0012950926320627332\n50 208.63461303710938 18.96678352355957 0.0009625746752135456\n60 161.9499969482422 14.722726821899414 0.0006962430197745562\n70 132.30828857421875 12.028026580810547 0.00020194215176161379\n80 115.37997436523438 10.48908805847168 0.00043812012881971896\n90 105.11175537109375 9.555614471435547 0.0002664974599611014\n100 96.4204330444336 8.765493392944336 0.000300785293802619\n110 81.88284301757812 7.443894863128662 0.00013955438043922186\n120 72.55297088623047 6.595724105834961 0.0002432800829410553\n130 62.291873931884766 5.66289758682251 0.00012828654143959284\n140 52.03126525878906 4.730114936828613 0.00024562733597122133\n150 43.03444290161133 3.912222146987915 9.249544382328168e-05\n160 33.83195877075195 3.0756325721740723 0.0001509079447714612\n170 25.59825325012207 2.3271141052246094 0.00013125757686793804\n180 21.262353897094727 1.9329413175582886 0.00016264778969343752\n190 16.029386520385742 1.4572169780731201 7.157359505072236e-05\n200 13.784917831420898 1.2531743049621582 8.820992661640048e-05\n210 11.188087463378906 1.0170989036560059 0.00021658511832356453\n220 9.78081226348877 0.8891647458076477 0.00010288815974490717\n230 8.847891807556152 0.8043537735939026 0.00016892356507014483\n240 8.186574935913086 0.7442340850830078 0.00017170557111967355\n250 7.486828327178955 0.6806207895278931 0.00012485033948905766\n260 6.966904640197754 0.6333549618721008 0.00015752176113892347\n270 6.662234306335449 0.605657696723938 9.707448043627664e-05\n280 6.030736923217773 0.548248827457428 0.00010645954171195626\n290 5.770167350769043 0.5245606899261475 0.0001459206541767344\n300 5.264832019805908 0.47862109541893005 7.16010617907159e-05\n310 4.858846187591553 0.44171327352523804 0.00020607358601409942\n320 4.620818614959717 0.4200744330883026 6.573277642019093e-05\n330 4.481804847717285 0.4074367880821228 0.0001630236947676167\n340 4.07119607925415 0.3701087236404419 0.00010188483429374173\n350 3.9176626205444336 0.35615113377571106 0.00010924797970801592\n360 3.7637410163879395 0.3421582579612732 8.868869190337136e-05\n370 3.7831647396087646 0.34392404556274414 0.00010947888949885964\n380 3.469775676727295 0.31543415784835815 4.412163980305195e-05\n390 3.2200698852539062 0.29273363947868347 0.0001553001784486696\n400 3.1403350830078125 0.28548499941825867 7.282436854438856e-05\n410 2.86068058013916 0.2600618600845337 9.535343997413293e-05\n420 3.1042640209198 0.28220582008361816 0.00011526865273481235\n430 2.748929262161255 0.2499026507139206 0.00018187687965109944\n440 2.6330459117889404 0.23936781287193298 0.00015040028665680438\n450 2.662119150161743 0.24201081693172455 7.504200766561553e-05\n460 2.5109305381774902 0.2282664179801941 3.9411501347785816e-05\n470 2.5104455947875977 0.2282223254442215 0.0001296202972298488\n480 2.477301597595215 0.22520923614501953 0.00010228652536170557\n490 2.308311939239502 0.20984655618667603 6.694379408145323e-05\n500 2.1339402198791504 0.19399456679821014 0.00022124838142190129\n510 2.309166431427002 0.20992420613765717 0.00013526435941457748\n520 2.1084253787994385 0.19167503714561462 0.0001686411997070536\n530 2.030536413192749 0.18459422886371613 7.450384873664007e-05\n540 2.0357561111450195 0.185068741440773 0.00011227897630305961\n550 1.9330636262893677 0.1757330596446991 0.00013960171781945974\n560 1.9888349771499634 0.18080316483974457 9.895607945509255e-05\n570 1.7447638511657715 0.1586148887872696 0.00010833295527845621\n580 1.6976876258850098 0.15433524549007416 0.00012656244507525116\n590 1.7392055988311768 0.1581096053123474 6.34089155937545e-05\n600 1.8462191820144653 0.16783809661865234 0.0001396091829519719\n610 1.745456337928772 0.1586778610944748 0.00013960186333861202\n620 1.5916372537612915 0.1446942836046219 0.00016315653920173645\n630 1.7329643964767456 0.15754221379756927 5.714560393244028e-05\n640 1.614901065826416 0.1468091905117035 0.0001757888967404142\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c2f13cf68835>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrloss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrloss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0moloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss/model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "exname = 'model_bip_lander_big_residual'\n",
    "os.system('mkdir tb/' + exname)\n",
    "writer = SummaryWriter('tb/'+exname)\n",
    "\n",
    "bsize = 2048\n",
    "loss = 0; rloss=0; oloss=0;\n",
    "for ep in range(10000):\n",
    "    obs = env.reset()\n",
    "    if ep%1==0:\n",
    "        for step in range(200):\n",
    "            a = env.action_space.sample()\n",
    "            oldobs = obs\n",
    "            obs, r, done, info = env.step(a)\n",
    "            repbuff.add(oldobs, a, r, obs)\n",
    "\n",
    "            if done:\n",
    "                obs = env.reset()\n",
    "                break\n",
    "    if bsize*3 > len(repbuff):\n",
    "        continue\n",
    "    oldobs, a, r, obs = repbuff.get(bsize)\n",
    "\n",
    "    for opt_step in range(3):\n",
    "        pr, pobs = model(oldobs, a)\n",
    "        rloss = ((pr-r)**2).mean()\n",
    "        oloss = ((pobs-obs)**2).mean()\n",
    "        loss = rloss + 10*torch.abs(rloss/oloss).detach()*oloss\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    writer.add_scalar('loss/model', loss.item(), ep)\n",
    "    writer.add_scalar('loss/reward', rloss.item(), ep)\n",
    "    writer.add_scalar('loss/states', oloss.item(), ep)\n",
    "    \n",
    "    if ep%10==0:\n",
    "        print(ep, loss.item(),rloss.item(), oloss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "349494"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(repbuff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(obs, nsmpls=100, tlen=10):\n",
    "    maxr = float('-inf')\n",
    "    obs = obs.repeat(nsmpls, 1)\n",
    "    rs = torch.zeros(nsmpls, 1)\n",
    "    for t in range(tlen):\n",
    "        a = nsample(env.action_space.sample, nsmpls)\n",
    "#         print(a, \"ass\")\n",
    "#         print(obs.shape, a.shape)\n",
    "        r, obs = model(obs, a)\n",
    "        rs += r\n",
    "        a = a.unsqueeze(1)\n",
    "        if t==0:\n",
    "            ass = a\n",
    "        else:\n",
    "            ass = torch.cat((ass, a), dim=1)\n",
    "    ii = torch.argmax(rs)\n",
    "    #print(rs[ii])\n",
    "#     print(ass)\n",
    "    return ass[ii]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([1.5685])"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "policy(torch.zeros(1, 3))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4,), (24,))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample().shape, env.observation_space.sample().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([100, 1])"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "def nsample(smpl_func, n=100):\n",
    "    toreturn = np.expand_dims(smpl_func(), axis=0)\n",
    "    for i in range(n-1):\n",
    "        new = np.expand_dims(smpl_func(), axis=0)\n",
    "        toreturn = np.concatenate((toreturn, new), axis=0)\n",
    "    return torch.tensor(toreturn, dtype=torch.float)\n",
    "\n",
    "nsample(env.action_space.sample).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showit():\n",
    "    dons = 0\n",
    "    observation = env.reset()\n",
    "    for t in range(2000):\n",
    "            env.render()\n",
    "            obser = np.expand_dims(observation, axis=0)\n",
    "            ass = policy(torch.tensor(obser).float(), 100, 30)\n",
    "            observation, reward, done, info = env.step(ass[0].numpy())\n",
    "            #observation, reward, done, info = env.step(env.action_space.sample())\n",
    "            rp, op = model(torch.tensor(obser).float(), ass[0].unsqueeze(0))\n",
    "            print(rp.item())\n",
    "            print(reward)\n",
    "            print(op)\n",
    "            print(obs)\n",
    "            print((\"---\"+str(t)+\"---\")*10)\n",
    "            \n",
    "            dons += done\n",
    "            if done:\n",
    "                print(\"r\", reward)\n",
    "                break\n",
    "            time.sleep(0.005)\n",
    "            print(t, \"/200\", reward, end='\\r')\n",
    "\n",
    "env.close()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "AddBackward0>)\ntensor([[ 0.9948,  0.1020,  1.7881],\n        [-0.8947, -0.4468,  7.4100],\n        [-0.8634,  0.5046, -5.6968],\n        ...,\n        [ 0.0617, -0.9981,  5.1603],\n        [ 0.4373,  0.8993, -1.4300],\n        [ 0.4022, -0.9155, -1.6348]])\n---133------133------133------133------133------133------133------133------133------133---\n133 /200 -0.009278881078197005-0.04819381237030029\n-0.014081505706157266\ntensor([[ 0.9962,  0.0425, -0.1520]], grad_fn=<AddBackward0>)\ntensor([[ 0.9948,  0.1020,  1.7881],\n        [-0.8947, -0.4468,  7.4100],\n        [-0.8634,  0.5046, -5.6968],\n        ...,\n        [ 0.0617, -0.9981,  5.1603],\n        [ 0.4373,  0.8993, -1.4300],\n        [ 0.4022, -0.9155, -1.6348]])\n---134------134------134------134------134------134------134------134------134------134---\n134 /200 -0.014081505706157266-0.02733445167541504\n-0.004701965602051974\ntensor([[ 0.9986,  0.0429, -0.0174]], grad_fn=<AddBackward0>)\ntensor([[ 0.9948,  0.1020,  1.7881],\n        [-0.8947, -0.4468,  7.4100],\n        [-0.8634,  0.5046, -5.6968],\n        ...,\n        [ 0.0617, -0.9981,  5.1603],\n        [ 0.4373,  0.8993, -1.4300],\n        [ 0.4022, -0.9155, -1.6348]])\n---135------135------135------135------135------135------135------135------135------135---\n-0.06760746240615845\n-0.003721370805965661\ntensor([[ 0.9977,  0.0366, -0.1625]], grad_fn=<AddBackward0>)\ntensor([[ 0.9948,  0.1020,  1.7881],\n        [-0.8947, -0.4468,  7.4100],\n        [-0.8634,  0.5046, -5.6968],\n        ...,\n        [ 0.0617, -0.9981,  5.1603],\n        [ 0.4373,  0.8993, -1.4300],\n        [ 0.4022, -0.9155, -1.6348]])\n---136------136------136------136------136------136------136------136------136------136---\n136 /200 -0.003721370805965661-0.023620426654815674\n-0.00407586706258253\ntensor([[ 1.0007,  0.0288, -0.1157]], grad_fn=<AddBackward0>)\ntensor([[ 0.9948,  0.1020,  1.7881],\n        [-0.8947, -0.4468,  7.4100],\n        [-0.8634,  0.5046, -5.6968],\n        ...,\n        [ 0.0617, -0.9981,  5.1603],\n        [ 0.4373,  0.8993, -1.4300],\n        [ 0.4022, -0.9155, -1.6348]])\n---137------137------137------137------137------137------137------137------137------137---\n0.027852118015289307\n-0.0025713290863499786\ntensor([[ 1.0018,  0.0211, -0.1639]], grad_fn=<AddBackward0>)\ntensor([[ 0.9948,  0.1020,  1.7881],\n        [-0.8947, -0.4468,  7.4100],\n        [-0.8634,  0.5046, -5.6968],\n        ...,\n        [ 0.0617, -0.9981,  5.1603],\n        [ 0.4373,  0.8993, -1.4300],\n        [ 0.4022, -0.9155, -1.6348]])\n---138------138------138------138------138------138------138------138------138------138---\n138 /200 -0.0025713290863499786-0.028142333030700684\n-0.0039368872232649465\ntensor([[ 0.9997,  0.0194, -0.0293]], grad_fn=<AddBackward0>)\ntensor([[ 0.9948,  0.1020,  1.7881],\n        [-0.8947, -0.4468,  7.4100],\n        [-0.8634,  0.5046, -5.6968],\n        ...,\n        [ 0.0617, -0.9981,  5.1603],\n        [ 0.4373,  0.8993, -1.4300],\n        [ 0.4022, -0.9155, -1.6348]])\n---139------139------139------139------139------139------139------139------139------139---\n139 /200 -0.00393688722326494650.019675910472869873\n-0.000644989487163816\ntensor([[1.0034, 0.0211, 0.0023]], grad_fn=<AddBackward0>)\ntensor([[ 0.9948,  0.1020,  1.7881],\n        [-0.8947, -0.4468,  7.4100],\n        [-0.8634,  0.5046, -5.6968],\n        ...,\n        [ 0.0617, -0.9981,  5.1603],\n        [ 0.4373,  0.8993, -1.4300],\n        [ 0.4022, -0.9155, -1.6348]])\n---140------140------140------140------140------140------140------140------140------140---\n140 /200 -0.000644989487163816-0.11728554964065552\n-0.0029314081447530224\ntensor([[ 0.9968,  0.0130, -0.1992]], grad_fn=<AddBackward0>)\ntensor([[ 0.9948,  0.1020,  1.7881],\n        [-0.8947, -0.4468,  7.4100],\n        [-0.8634,  0.5046, -5.6968],\n        ...,\n        [ 0.0617, -0.9981,  5.1603],\n        [ 0.4373,  0.8993, -1.4300],\n        [ 0.4022, -0.9155, -1.6348]])\n---141------141------141------141------141------141------141------141------141------141---\n141 /200 -0.0029314081447530224-0.1501602828502655\n-0.005800158233663687\ntensor([[1.0026, 0.0162, 0.0129]], grad_fn=<AddBackward0>)\ntensor([[ 0.9948,  0.1020,  1.7881],\n        [-0.8947, -0.4468,  7.4100],\n        [-0.8634,  0.5046, -5.6968],\n        ...,\n        [ 0.0617, -0.9981,  5.1603],\n        [ 0.4373,  0.8993, -1.4300],\n        [ 0.4022, -0.9155, -1.6348]])\n---142------142------142------142------142------142------142------142------142------142---\n142 /200 -0.005800158233663687-0.2637481391429901\n-0.0026912389318310337\ntensor([[1.0038, 0.0340, 0.2594]], grad_fn=<AddBackward0>)\ntensor([[ 0.9948,  0.1020,  1.7881],\n        [-0.8947, -0.4468,  7.4100],\n        [-0.8634,  0.5046, -5.6968],\n        ...,\n        [ 0.0617, -0.9981,  5.1603],\n        [ 0.4373,  0.8993, -1.4300],\n        [ 0.4022, -0.9155, -1.6348]])\n---143------143------143------143------143------143------143------143------143------143---\n143 /200 -0.0026912389318310337-0.21016937494277954\n-0.01014849030177808\ntensor([[0.9973, 0.0325, 0.0478]], grad_fn=<AddBackward0>)\ntensor([[ 0.9948,  0.1020,  1.7881],\n        [-0.8947, -0.4468,  7.4100],\n        [-0.8634,  0.5046, -5.6968],\n        ...,\n        [ 0.0617, -0.9981,  5.1603],\n        [ 0.4373,  0.8993, -1.4300],\n        [ 0.4022, -0.9155, -1.6348]])\n---144------144------144------144------144------144------144------144------144------144---\n144 /200 -0.01014849030177808-0.04239320755004883\n-0.002399821957934675\ntensor([[ 0.9986,  0.0255, -0.0842]], grad_fn=<AddBackward0>)\ntensor([[ 0.9948,  0.1020,  1.7881],\n        [-0.8947, -0.4468,  7.4100],\n        [-0.8634,  0.5046, -5.6968],\n        ...,\n        [ 0.0617, -0.9981,  5.1603],\n        [ 0.4373,  0.8993, -1.4300],\n        [ 0.4022, -0.9155, -1.6348]])\n---145------145------145------145------145------145------145------145------145------145---\n145 /200 -0.002399821957934675-0.0008767247200012207\n-0.0017606835440606588\ntensor([[0.9986, 0.0244, 0.0107]], grad_fn=<AddBackward0>)\ntensor([[ 0.9948,  0.1020,  1.7881],\n        [-0.8947, -0.4468,  7.4100],\n        [-0.8634,  0.5046, -5.6968],\n        ...,\n        [ 0.0617, -0.9981,  5.1603],\n        [ 0.4373,  0.8993, -1.4300],\n        [ 0.4022, -0.9155, -1.6348]])\n---146------146------146------146------146------146------146------146------146------146---\n-0.08486706018447876\n-0.002668639607561974\ntensor([[ 0.9978,  0.0182, -0.1652]], grad_fn=<AddBackward0>)\ntensor([[ 0.9948,  0.1020,  1.7881],\n        [-0.8947, -0.4468,  7.4100],\n        [-0.8634,  0.5046, -5.6968],\n        ...,\n        [ 0.0617, -0.9981,  5.1603],\n        [ 0.4373,  0.8993, -1.4300],\n        [ 0.4022, -0.9155, -1.6348]])\n---147------147------147------147------147------147------147------147------147------147---\n147 /200 -0.0026686396075619740.020301103591918945\n-0.0030670387438642005\ntensor([[ 1.0052,  0.0089, -0.1689]], grad_fn=<AddBackward0>)\ntensor([[ 0.9948,  0.1020,  1.7881],\n        [-0.8947, -0.4468,  7.4100],\n        [-0.8634,  0.5046, -5.6968],\n        ...,\n        [ 0.0617, -0.9981,  5.1603],\n        [ 0.4373,  0.8993, -1.4300],\n        [ 0.4022, -0.9155, -1.6348]])\n---148------148------148------148------148------148------148------148------148------148---\n148 /200 -0.0030670387438642005-0.33478304743766785\n-0.005548569258964042\ntensor([[1.0062, 0.0237, 0.1080]], grad_fn=<AddBackward0>)\ntensor([[ 0.9948,  0.1020,  1.7881],\n        [-0.8947, -0.4468,  7.4100],\n        [-0.8634,  0.5046, -5.6968],\n        ...,\n        [ 0.0617, -0.9981,  5.1603],\n        [ 0.4373,  0.8993, -1.4300],\n        [ 0.4022, -0.9155, -1.6348]])\n---149------149------149------149------149------149------149------149------149------149---\n149 /200 -0.005548569258964042-0.010861039161682129\n-0.0017617646349564972\ntensor([[0.9994, 0.0253, 0.1864]], grad_fn=<AddBackward0>)\ntensor([[ 0.9948,  0.1020,  1.7881],\n        [-0.8947, -0.4468,  7.4100],\n        [-0.8634,  0.5046, -5.6968],\n        ...,\n        [ 0.0617, -0.9981,  5.1603],\n        [ 0.4373,  0.8993, -1.4300],\n        [ 0.4022, -0.9155, -1.6348]])\n---150------150------150------150------150------150------150------150------150------150---\n-0.030947506427764893\n-0.004796054660694928\ntensor([[1.0000, 0.0405, 0.2654]], grad_fn=<AddBackward0>)\ntensor([[ 0.9948,  0.1020,  1.7881],\n        [-0.8947, -0.4468,  7.4100],\n        [-0.8634,  0.5046, -5.6968],\n        ...,\n        [ 0.0617, -0.9981,  5.1603],\n        [ 0.4373,  0.8993, -1.4300],\n        [ 0.4022, -0.9155, -1.6348]])\n---151------151------151------151------151------151------151------151------151------151---\n151 /200 -0.004796054660694928-0.17544370889663696\n-0.011192176545600088\ntensor([[0.9966, 0.0491, 0.0943]], grad_fn=<AddBackward0>)\ntensor([[ 0.9948,  0.1020,  1.7881],\n        [-0.8947, -0.4468,  7.4100],\n        [-0.8634,  0.5046, -5.6968],\n        ...,\n        [ 0.0617, -0.9981,  5.1603],\n        [ 0.4373,  0.8993, -1.4300],\n        [ 0.4022, -0.9155, -1.6348]])\n---152------152------152------152------152------152------152------152------152------152---\n152 /200 -0.0111921765456000880.014770925045013428\n-0.003186260376310425\ntensor([[1.0020, 0.0494, 0.1166]], grad_fn=<AddBackward0>)\ntensor([[ 0.9948,  0.1020,  1.7881],\n        [-0.8947, -0.4468,  7.4100],\n        [-0.8634,  0.5046, -5.6968],\n        ...,\n        [ 0.0617, -0.9981,  5.1603],\n        [ 0.4373,  0.8993, -1.4300],\n        [ 0.4022, -0.9155, -1.6348]])\n---153------153------153------153------153------153------153------153------153------153---\n153 /200 -0.003186260376310425-0.0035265088081359863\n-0.004517765256616873\ntensor([[1.0018, 0.0562, 0.1015]], grad_fn=<AddBackward0>)\ntensor([[ 0.9948,  0.1020,  1.7881],\n        [-0.8947, -0.4468,  7.4100],\n        [-0.8634,  0.5046, -5.6968],\n        ...,\n        [ 0.0617, -0.9981,  5.1603],\n        [ 0.4373,  0.8993, -1.4300],\n        [ 0.4022, -0.9155, -1.6348]])\n---154------154------154------154------154------154------154------154------154------154---\n154 /200 -0.004517765256616873-0.016510844230651855\n-0.00478036772651904\ntensor([[1.0002, 0.0600, 0.0682]], grad_fn=<AddBackward0>)\ntensor([[ 0.9948,  0.1020,  1.7881],\n        [-0.8947, -0.4468,  7.4100],\n        [-0.8634,  0.5046, -5.6968],\n        ...,\n        [ 0.0617, -0.9981,  5.1603],\n        [ 0.4373,  0.8993, -1.4300],\n        [ 0.4022, -0.9155, -1.6348]])\n---155------155------155------155------155------155------155------155------155------155---\n-0.01976555585861206\n-0.004829403515208567\ntensor([[0.9992, 0.0614, 0.0185]], grad_fn=<AddBackward0>)\ntensor([[ 0.9948,  0.1020,  1.7881],\n        [-0.8947, -0.4468,  7.4100],\n        [-0.8634,  0.5046, -5.6968],\n        ...,\n        [ 0.0617, -0.9981,  5.1603],\n        [ 0.4373,  0.8993, -1.4300],\n        [ 0.4022, -0.9155, -1.6348]])\n---156------156------156------156------156------156------156------156------156------156---\n156 /200 -0.004829403515208567-0.042133986949920654\n-0.004397455345199804\ntensor([[0.9992, 0.0697, 0.1520]], grad_fn=<AddBackward0>)\ntensor([[ 0.9948,  0.1020,  1.7881],\n        [-0.8947, -0.4468,  7.4100],\n        [-0.8634,  0.5046, -5.6968],\n        ...,\n        [ 0.0617, -0.9981,  5.1603],\n        [ 0.4373,  0.8993, -1.4300],\n        [ 0.4022, -0.9155, -1.6348]])\n---157------157------157------157------157------157------157------157------157------157---\n157 /200 -0.004397455345199804-0.09667623043060303\n-0.007988497745896292\ntensor([[1.0001, 0.0869, 0.3001]], grad_fn=<AddBackward0>)\ntensor([[ 0.9948,  0.1020,  1.7881],\n        [-0.8947, -0.4468,  7.4100],\n        [-0.8634,  0.5046, -5.6968],\n        ...,\n        [ 0.0617, -0.9981,  5.1603],\n        [ 0.4373,  0.8993, -1.4300],\n        [ 0.4022, -0.9155, -1.6348]])\n---158------158------158------158------158------158------158------158------158------158---\n158 /200 -0.007988497745896292-0.14675521850585938\n-0.01788359523910503\ntensor([[0.9951, 0.1013, 0.2105]], grad_fn=<AddBackward0>)\ntensor([[ 0.9948,  0.1020,  1.7881],\n        [-0.8947, -0.4468,  7.4100],\n        [-0.8634,  0.5046, -5.6968],\n        ...,\n        [ 0.0617, -0.9981,  5.1603],\n        [ 0.4373,  0.8993, -1.4300],\n        [ 0.4022, -0.9155, -1.6348]])\n---159------159------159------159------159------159------159------159------159------159---\n159 /200 -0.01788359523910503-0.27151328325271606\n-0.017573255800663035\ntensor([[0.9931, 0.1011, 0.0193]], grad_fn=<AddBackward0>)\ntensor([[ 0.9948,  0.1020,  1.7881],\n        [-0.8947, -0.4468,  7.4100],\n        [-0.8634,  0.5046, -5.6968],\n        ...,\n        [ 0.0617, -0.9981,  5.1603],\n        [ 0.4373,  0.8993, -1.4300],\n        [ 0.4022, -0.9155, -1.6348]])\n---160------160------160------160------160------160------160------160------160------160---\n160 /200 -0.017573255800663035-0.19747453927993774\n-0.013314807487014819\ntensor([[ 0.9950,  0.0894, -0.1849]], grad_fn=<AddBackward0>)\ntensor([[ 0.9948,  0.1020,  1.7881],\n        [-0.8947, -0.4468,  7.4100],\n        [-0.8634,  0.5046, -5.6968],\n        ...,\n        [ 0.0617, -0.9981,  5.1603],\n        [ 0.4373,  0.8993, -1.4300],\n        [ 0.4022, -0.9155, -1.6348]])\n---161------161------161------161------161------161------161------161------161------161---\n161 /200 -0.013314807487014819-0.03651696443557739\n-0.011354618419022884\ntensor([[ 0.9938,  0.0829, -0.0895]], grad_fn=<AddBackward0>)\ntensor([[ 0.9948,  0.1020,  1.7881],\n        [-0.8947, -0.4468,  7.4100],\n        [-0.8634,  0.5046, -5.6968],\n        ...,\n        [ 0.0617, -0.9981,  5.1603],\n        [ 0.4373,  0.8993, -1.4300],\n        [ 0.4022, -0.9155, -1.6348]])\n---162------162------162------162------162------162------162------162------162------162---\n162 /200 -0.011354618419022884-0.10605770349502563\n-0.010303737202638719\ntensor([[ 0.9961,  0.0718, -0.2506]], grad_fn=<AddBackward0>)\ntensor([[ 0.9948,  0.1020,  1.7881],\n        [-0.8947, -0.4468,  7.4100],\n        [-0.8634,  0.5046, -5.6968],\n        ...,\n        [ 0.0617, -0.9981,  5.1603],\n        [ 0.4373,  0.8993, -1.4300],\n        [ 0.4022, -0.9155, -1.6348]])\n---163------163------163------163------163------163------163------163------163------163---\n163 /200 -0.010303737202638719-0.015939056873321533\n-0.012339483753375284\ntensor([[ 0.9999,  0.0547, -0.3384]], grad_fn=<AddBackward0>)\ntensor([[ 0.9948,  0.1020,  1.7881],\n        [-0.8947, -0.4468,  7.4100],\n        [-0.8634,  0.5046, -5.6968],\n        ...,\n        [ 0.0617, -0.9981,  5.1603],\n        [ 0.4373,  0.8993, -1.4300],\n        [ 0.4022, -0.9155, -1.6348]])\n---164------164------164------164------164------164------164------164------164------164---\n164 /200 -0.0123394837533752840.0022800564765930176\n-0.014853095995055509\ntensor([[ 1.0032,  0.0366, -0.3818]], grad_fn=<AddBackward0>)\ntensor([[ 0.9948,  0.1020,  1.7881],\n        [-0.8947, -0.4468,  7.4100],\n        [-0.8634,  0.5046, -5.6968],\n        ...,\n        [ 0.0617, -0.9981,  5.1603],\n        [ 0.4373,  0.8993, -1.4300],\n        [ 0.4022, -0.9155, -1.6348]])\n---165------165------165------165------165------165------165------165------165------165---\n-0.21496042609214783\n-0.018001324954751433\ntensor([[ 1.0041,  0.0311, -0.1313]], grad_fn=<AddBackward0>)\ntensor([[ 0.9948,  0.1020,  1.7881],\n        [-0.8947, -0.4468,  7.4100],\n        [-0.8634,  0.5046, -5.6968],\n        ...,\n        [ 0.0617, -0.9981,  5.1603],\n        [ 0.4373,  0.8993, -1.4300],\n        [ 0.4022, -0.9155, -1.6348]])\n---166------166------166------166------166------166------166------166------166------166---\n166 /200 -0.0180013249547514330.028410613536834717\n-0.003014516729585105\ntensor([[ 1.0017,  0.0169, -0.1937]], grad_fn=<AddBackward0>)\ntensor([[ 0.9948,  0.1020,  1.7881],\n        [-0.8947, -0.4468,  7.4100],\n        [-0.8634,  0.5046, -5.6968],\n        ...,\n        [ 0.0617, -0.9981,  5.1603],\n        [ 0.4373,  0.8993, -1.4300],\n        [ 0.4022, -0.9155, -1.6348]])\n---167------167------167------167------167------167------167------167------167------167---\n167 /200 -0.003014516729585105-0.022808372974395752\n-0.005436396809707436\ntensor([[ 0.9985,  0.0021, -0.3459]], grad_fn=<AddBackward0>)\ntensor([[ 0.9948,  0.1020,  1.7881],\n        [-0.8947, -0.4468,  7.4100],\n        [-0.8634,  0.5046, -5.6968],\n        ...,\n        [ 0.0617, -0.9981,  5.1603],\n        [ 0.4373,  0.8993, -1.4300],\n        [ 0.4022, -0.9155, -1.6348]])\n---168------168------168------168------168------168------168------168------168------168---\n168 /200 -0.005436396809707436-0.46041563153266907\n-0.01592420161815263\ntensor([[ 1.0090,  0.0086, -0.0412]], grad_fn=<AddBackward0>)\ntensor([[ 0.9948,  0.1020,  1.7881],\n        [-0.8947, -0.4468,  7.4100],\n        [-0.8634,  0.5046, -5.6968],\n        ...,\n        [ 0.0617, -0.9981,  5.1603],\n        [ 0.4373,  0.8993, -1.4300],\n        [ 0.4022, -0.9155, -1.6348]])\n---169------169------169------169------169------169------169------169------169------169---\n-0.09689432382583618\n-0.0024118526281374465\ntensor([[ 0.9964, -0.0145, -0.2686]], grad_fn=<AddBackward0>)\ntensor([[ 0.9948,  0.1020,  1.7881],\n        [-0.8947, -0.4468,  7.4100],\n        [-0.8634,  0.5046, -5.6968],\n        ...,\n        [ 0.0617, -0.9981,  5.1603],\n        [ 0.4373,  0.8993, -1.4300],\n        [ 0.4022, -0.9155, -1.6348]])\n---170------170------170------170------170------170------170------170------170------170---\n170 /200 -0.00241185262813744650.0033274292945861816\n-0.007142800146778212\ntensor([[ 1.0049, -0.0290, -0.2655]], grad_fn=<AddBackward0>)\ntensor([[ 0.9948,  0.1020,  1.7881],\n        [-0.8947, -0.4468,  7.4100],\n        [-0.8634,  0.5046, -5.6968],\n        ...,\n        [ 0.0617, -0.9981,  5.1603],\n        [ 0.4373,  0.8993, -1.4300],\n        [ 0.4022, -0.9155, -1.6348]])\n---171------171------171------171------171------171------171------171------171------171---\n171 /200 -0.007142800146778212-0.07149577140808105\n-0.00863220246971854\ntensor([[ 0.9999, -0.0322, -0.0968]], grad_fn=<AddBackward0>)\ntensor([[ 0.9948,  0.1020,  1.7881],\n        [-0.8947, -0.4468,  7.4100],\n        [-0.8634,  0.5046, -5.6968],\n        ...,\n        [ 0.0617, -0.9981,  5.1603],\n        [ 0.4373,  0.8993, -1.4300],\n        [ 0.4022, -0.9155, -1.6348]])\n---172------172------172------172------172------172------172------172------172------172---\n172 /200 -0.008632202469718540.021273672580718994\n-0.0017205306355603015\ntensor([[ 1.0028, -0.0371, -0.0607]], grad_fn=<AddBackward0>)\ntensor([[ 0.9948,  0.1020,  1.7881],\n        [-0.8947, -0.4468,  7.4100],\n        [-0.8634,  0.5046, -5.6968],\n        ...,\n        [ 0.0617, -0.9981,  5.1603],\n        [ 0.4373,  0.8993, -1.4300],\n        [ 0.4022, -0.9155, -1.6348]])\n---173------173------173------173------173------173------173------173------173------173---\n173 /200 -0.0017205306355603015-0.01405400037765503\n-0.0022201956629807175\ntensor([[ 1.0010, -0.0326,  0.0640]], grad_fn=<AddBackward0>)\ntensor([[ 0.9948,  0.1020,  1.7881],\n        [-0.8947, -0.4468,  7.4100],\n        [-0.8634,  0.5046, -5.6968],\n        ...,\n        [ 0.0617, -0.9981,  5.1603],\n        [ 0.4373,  0.8993, -1.4300],\n        [ 0.4022, -0.9155, -1.6348]])\n---174------174------174------174------174------174------174------174------174------174---\n174 /200 -0.00222019566298071750.027461588382720947\n-0.0016649188619404837\ntensor([[ 1.0001, -0.0252,  0.1373]], grad_fn=<AddBackward0>)\ntensor([[ 0.9948,  0.1020,  1.7881],\n        [-0.8947, -0.4468,  7.4100],\n        [-0.8634,  0.5046, -5.6968],\n        ...,\n        [ 0.0617, -0.9981,  5.1603],\n        [ 0.4373,  0.8993, -1.4300],\n        [ 0.4022, -0.9155, -1.6348]])\n---175------175------175------175------175------175------175------175------175------175---\n175 /200 -0.0016649188619404837-0.21114665269851685\n-0.005523325918886678\ntensor([[ 0.9962, -0.0305, -0.1302]], grad_fn=<AddBackward0>)\ntensor([[ 0.9948,  0.1020,  1.7881],\n        [-0.8947, -0.4468,  7.4100],\n        [-0.8634,  0.5046, -5.6968],\n        ...,\n        [ 0.0617, -0.9981,  5.1603],\n        [ 0.4373,  0.8993, -1.4300],\n        [ 0.4022, -0.9155, -1.6348]])\n---176------176------176------176------176------176------176------176------176------176---\n176 /200 -0.005523325918886678"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e30819bc979d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshowit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-bae398ed89ac>\u001b[0m in \u001b[0;36mshowit\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mobser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mass\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;31m#observation, reward, done, info = env.step(env.action_space.sample())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-57c74f9de887>\u001b[0m in \u001b[0;36mpolicy\u001b[0;34m(obs, nsmpls, tlen)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnsmpls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnsmpls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#         print(a, \"ass\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#         print(obs.shape, a.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-02678068f8ee>\u001b[0m in \u001b[0;36mnsample\u001b[0;34m(smpl_func, n)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtoreturn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmpl_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmpl_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mtoreturn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoreturn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoreturn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gym/spaces/box.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    115\u001b[0m             size=upp_bounded[upp_bounded].shape) + self.high[upp_bounded]\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         sample[bounded] = self.np_random.uniform(low=self.low[bounded],\n\u001b[0m\u001b[1;32m    118\u001b[0m                                             \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbounded\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                                             size=bounded[bounded].shape)\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.uniform\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mall\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "showit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}