{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    # in the process of building 
    
    
    
    
    
    
    
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from collections import deque\n",
    "import time\n",
    "import math\n",
    "import gym\n",
    "import random\n",
    "env = gym.make('Pendulum-v0')\n",
    "env.action_space, env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy(nn.Module):\n",
    "    def __init__(self, idim, h1dim, h2dim, odim):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(idim, h1dim)\n",
    "        self.lin2 = nn.Linear(h1dim, odim)\n",
    "    def forward(self, x):\n",
    "        h = self.lin1(x)\n",
    "        h = F.relu(h)\n",
    "        h = self.lin2(h)\n",
    "        h = torch.tanh(h)\n",
    "        return h\n",
    "    def act(self, x, noise=0.5):\n",
    "        h = torch.tensor(x, dtype=torch.float)\n",
    "        h = self.forward(h)\n",
    "        zeros = torch.zeros(h.shape, dtype=torch.float)\n",
    "        noises = torch.ones(h.shape, dtype=torch.float)*noise\n",
    "        dist = torch.distributions.Normal(zeros, noises)\n",
    "        h += dist.sample()\n",
    "        h = torch.clamp(h, -1, 1)\n",
    "        hnumpy = h.detach().numpy()\n",
    "        return hnumpy, h\n",
    "    \n",
    "class Q(nn.Module):\n",
    "    def __init__(self, idim, h1dim, h2dim, odim):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(idim, h1dim)\n",
    "        self.lin2 = nn.Linear(h1dim, odim)\n",
    "    def forward(self, x):\n",
    "        h = self.lin1(x)\n",
    "        h = F.relu(h)\n",
    "        h = self.lin2(h)\n",
    "        return h\n",
    "\n",
    "    \n",
    "class ReplayBuffer():\n",
    "    def __init__(self, max_len=100000):\n",
    "        self.old_obs = deque([])\n",
    "        self.a = deque([])\n",
    "        self.r = deque([])\n",
    "        self.obs = deque([])\n",
    "        self.size = max_len\n",
    "        self.length = 0\n",
    "        self.max_len = max_len\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    def remover(self):\n",
    "        if self.length > self.max_len:\n",
    "            self.a.popleft()\n",
    "            self.old_obs.popleft()\n",
    "            self.r.popleft()\n",
    "            self.obs.popleft()\n",
    "            self.length -= 1\n",
    "    def add(self, old_obs, a, r, obs):\n",
    "        self.old_obs.append(old_obs)\n",
    "        self.a.append(a)\n",
    "        self.r.append(r)\n",
    "        self.obs.append(obs)\n",
    "        self.length += 1\n",
    "        self.remover()\n",
    "    def get(self, bsize):\n",
    "        lidx = random.sample(range(0, self.length), bsize)\n",
    "        old_obs = [self.old_obs[i] for i in lidx]\n",
    "        a       = [self.a[i] for i in lidx]\n",
    "        r       = [self.r[i] for i in lidx]\n",
    "        obs     = [self.obs[i] for i in lidx]\n",
    "        \n",
    "        old_obs = torch.tensor(list(old_obs), dtype=torch.float).detach()\n",
    "        a       = torch.tensor(list(a)      , dtype=torch.float).detach()\n",
    "        r       = torch.tensor(list(r)      , dtype=torch.float).detach()\n",
    "        obs     = torch.tensor(list(obs)    , dtype=torch.float).detach()\n",
    "        return old_obs, a, r, obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsdim = env.observation_space.shape[0]\n",
    "adim = env.action_space.shape[0]\n",
    "maxer = Maxer(obsdim, 8, None, adim)\n",
    "q1 = Q(obsdim+adim, 8, None, 1)\n",
    "q2 = Q(obsdim+adim, 8, None, 1)\n",
    "import copy\n",
    "q1target = copy.deepcopy(q1)\n",
    "q2target = copy.deepcopy(q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "mopt = torch.optim.Adam(maxer.parameters(), lr=1000)\n",
    "qopt = torch.optim.Adam([{'params':q1.parameters()}, {'params':q2.parameters()}],     lr=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "repbuff = ReplayBuffer(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep=0.00000   r=-123456.00000   td=8.05621   mpl=-7.12157   buffsize=1000000.00000   \n",
      "ep=20.00000   r=-0.02688   td=2.30166   mpl=-1.49378   buffsize=1000000.00000   \n",
      "ep=40.00000   r=-0.02744   td=0.15492   mpl=-0.08916   buffsize=1000000.00000   \n",
      "ep=60.00000   r=-0.02739   td=0.01201   mpl=0.27264   buffsize=1000000.00000   \n",
      "ep=80.00000   r=-0.02806   td=0.00254   mpl=0.37469   buffsize=1000000.00000   \n",
      "ep=100.00000   r=-0.02674   td=0.00196   mpl=0.40920   buffsize=1000000.00000   \n",
      "ep=120.00000   r=-0.02717   td=0.00182   mpl=0.42659   buffsize=1000000.00000   \n",
      "ep=140.00000   r=-0.02686   td=0.00188   mpl=0.43965   buffsize=1000000.00000   \n",
      "ep=160.00000   r=-0.02635   td=0.00186   mpl=0.45075   buffsize=1000000.00000   \n",
      "ep=180.00000   r=-0.02625   td=0.00184   mpl=0.46173   buffsize=1000000.00000   \n",
      "ep=200.00000   r=-0.02766   td=0.00193   mpl=0.47204   buffsize=1000000.00000   \n",
      "ep=220.00000   r=-0.02586   td=0.00191   mpl=0.48232   buffsize=1000000.00000   \n",
      "ep=240.00000   r=-0.02763   td=1292.67309   mpl=-0.43716   buffsize=1000000.00000   \n",
      "ep=260.00000   r=-0.02669   td=86.96373   mpl=0.35484   buffsize=1000000.00000   \n",
      "ep=280.00000   r=-0.02626   td=5.77589   mpl=0.67619   buffsize=1000000.00000   \n",
      "ep=300.00000   r=-0.02558   td=0.38525   mpl=0.76607   buffsize=1000000.00000   \n",
      "ep=320.00000   r=-0.02697   td=0.02727   mpl=0.79606   buffsize=1000000.00000   \n",
      "ep=340.00000   r=-0.02743   td=0.00361   mpl=0.81338   buffsize=1000000.00000   \n",
      "ep=360.00000   r=-0.02538   td=0.00199   mpl=0.82566   buffsize=1000000.00000   \n",
      "ep=380.00000   r=-0.02765   td=0.00187   mpl=0.83754   buffsize=1000000.00000   \n",
      "ep=400.00000   r=-0.02812   td=0.00192   mpl=0.84731   buffsize=1000000.00000   \n",
      "ep=420.00000   r=-0.02613   td=0.00194   mpl=0.85734   buffsize=1000000.00000   \n",
      "ep=440.00000   r=-0.02630   td=0.00192   mpl=0.87274   buffsize=1000000.00000   \n",
      "ep=460.00000   r=-0.02612   td=0.00190   mpl=0.88356   buffsize=1000000.00000   \n",
      "ep=480.00000   r=-0.02611   td=0.00211   mpl=0.89297   buffsize=1000000.00000   \n",
      "ep=500.00000   r=-0.02620   td=0.13534   mpl=0.90357   buffsize=1000000.00000   \n",
      "ep=520.00000   r=-0.02696   td=0.01186   mpl=0.91536   buffsize=1000000.00000   \n",
      "ep=540.00000   r=-0.02694   td=0.05545   mpl=0.92524   buffsize=1000000.00000   \n",
      "ep=560.00000   r=-0.02751   td=0.16578   mpl=0.93691   buffsize=1000000.00000   \n",
      "ep=580.00000   r=-0.02615   td=0.01620   mpl=0.94680   buffsize=1000000.00000   \n",
      "ep=600.00000   r=-0.02761   td=0.13977   mpl=0.95926   buffsize=1000000.00000   \n",
      "ep=620.00000   r=-0.02649   td=0.01137   mpl=0.97093   buffsize=1000000.00000   \n",
      "ep=640.00000   r=-0.02705   td=0.18527   mpl=0.98163   buffsize=1000000.00000   \n",
      "ep=660.00000   r=-0.02638   td=0.02025   mpl=0.99203   buffsize=1000000.00000   \n",
      "ep=680.00000   r=-0.02632   td=0.09899   mpl=1.00235   buffsize=1000000.00000   \n",
      "ep=700.00000   r=-0.02841   td=0.01798   mpl=1.01357   buffsize=1000000.00000   \n",
      "ep=720.00000   r=-0.02687   td=0.03271   mpl=1.02441   buffsize=1000000.00000   \n",
      "ep=740.00000   r=-0.02752   td=0.19216   mpl=1.03490   buffsize=1000000.00000   \n",
      "ep=760.00000   r=-0.02671   td=0.01604   mpl=1.04599   buffsize=1000000.00000   \n",
      "ep=780.00000   r=-0.02726   td=0.11714   mpl=1.05676   buffsize=1000000.00000   \n",
      "ep=800.00000   r=-0.02680   td=0.04761   mpl=1.06743   buffsize=1000000.00000   \n",
      "ep=820.00000   r=-0.02668   td=0.02436   mpl=1.07724   buffsize=1000000.00000   \n",
      "ep=840.00000   r=-0.02740   td=0.06960   mpl=1.08843   buffsize=1000000.00000   \n",
      "ep=860.00000   r=-0.02729   td=0.15696   mpl=1.09984   buffsize=1000000.00000   \n",
      "ep=880.00000   r=-0.02745   td=0.01789   mpl=1.11027   buffsize=1000000.00000   \n",
      "ep=900.00000   r=-0.02549   td=0.06152   mpl=1.12115   buffsize=1000000.00000   \n",
      "ep=920.00000   r=-0.02679   td=0.01546   mpl=1.13190   buffsize=1000000.00000   \n",
      "ep=940.00000   r=-0.02720   td=0.03970   mpl=1.14202   buffsize=1000000.00000   \n",
      "ep=960.00000   r=-0.02643   td=0.21041   mpl=1.15257   buffsize=1000000.00000   \n",
      "ep=980.00000   r=-0.02759   td=0.02519   mpl=1.16323   buffsize=1000000.00000   \n",
      "ep=1000.00000   r=-0.02684   td=0.17937   mpl=1.17237   buffsize=1000000.00000   \n",
      "ep=1020.00000   r=-0.02672   td=0.01511   mpl=1.18217   buffsize=1000000.00000   \n",
      "ep=1040.00000   r=-0.02767   td=0.09726   mpl=1.19192   buffsize=1000000.00000   \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-239-b33b27224bfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaxer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mold_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mrepbuff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mrlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gym/wrappers/time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cannot call env.step() before calling reset()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_episode_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gym/envs/classic_control/continuous_mountain_car.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mreward\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvelocity\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "eps = 10000\n",
    "gamma = 1\n",
    "bsize = 512\n",
    "warmup = 0\n",
    "tdlp = LowPassFilter(1-1/30)\n",
    "rlp  = LowPassFilter(1-1/1000)\n",
    "mlp  = LowPassFilter(1-1/30)\n",
    "for ep in range(eps):\n",
    "    if ep%20:\n",
    "        obs = env.reset()\n",
    "        for step in range(2000):\n",
    "            if ep < warmup:\n",
    "                a = env.action_space.sample()\n",
    "            else:\n",
    "                a, _ = maxer.act(obs, 0.5)\n",
    "            old_obs = obs\n",
    "            obs, r, done, info = env.step(a)\n",
    "            repbuff.add(old_obs, a, r, obs)\n",
    "            rlp.step(r)\n",
    "            if done:\n",
    "                if step < 998:\n",
    "                    print(step, \"done\")\n",
    "                break\n",
    "            #env.render(); time.sleep(0.01)\n",
    "    \n",
    "    if bsize > len(repbuff):\n",
    "        continue\n",
    "    old_obs, a, r, obs = repbuff.get(bsize)\n",
    "    r = r.unsqueeze(-1)\n",
    "    #print(old_obs.shape, a.shape, r.shape, obs.shape)\n",
    "    for step in range(4):\n",
    "        in1 = torch.cat((maxer(obs).detach(), obs), dim=-1)\n",
    "        in2 = torch.cat((a, old_obs), dim=-1)\n",
    "        #print(in1.shape, in2.shape, r.shape, q(in2).shape)\n",
    "        y = torch.min(q1target(in1), q2target(in1))\n",
    "        td_error = ((r + gamma*y.detach() - q1(in2))**2).mean() + ((r + gamma*y.detach() - q2(in2))**2).mean()\n",
    "        qopt.zero_grad()\n",
    "        td_error.backward()\n",
    "        qopt.step()\n",
    "        tdlp.step(td_error.item())\n",
    "    if ep%2==0:\n",
    "        for step in range(4):\n",
    "            in1 = torch.cat((maxer(obs), obs), dim=-1)\n",
    "            loss = -q1(in1).mean()\n",
    "            mopt.zero_grad()\n",
    "            loss.backward()\n",
    "            mopt.step()\n",
    "            mlp.step(loss.item())\n",
    "\n",
    "    polyak(q1, q1target, 1-1/50)\n",
    "    polyak(q2, q2target, 1-1/50)\n",
    "    \n",
    "    if ep%20==0:\n",
    "        mprint(\"ep\", ep, \"r\", rlp.val, \"td\", tdlp.val, \"mpl\", mlp.val, \"buffsize\", len(repbuff))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499 /200\r"
     ]
    }
   ],
   "source": [
    "#env = gym.make('Pendulum-v0')\n",
    "observation = env.reset()\n",
    "for t in range(500):\n",
    "        env.render()\n",
    "        action, logprobs = maxer.act(observation, 0.01)\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            break\n",
    "        time.sleep(0.01)\n",
    "        print(t, \"/200\", end='\\r')\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LowPassFilter():\n",
    "    def __init__(self, alfa):\n",
    "        self.init_value = -123456\n",
    "        self.val = self.init_value\n",
    "        self.alfa = alfa\n",
    "    def step(self, newval):\n",
    "        if self.val == self.init_value:\n",
    "            self.val = newval\n",
    "        self.val = self.val*self.alfa + newval*(1-self.alfa)\n",
    "        \n",
    "def mprint(*args):\n",
    "    pr = \"\"\n",
    "    args = [[args[i*2], args[i*2+1]] for i in range(len(args)//2)]\n",
    "    for name, arg in args:\n",
    "        pr += name + \"=\"\n",
    "        if type(arg) == int:\n",
    "            arg = float(arg)\n",
    "        try:\n",
    "            arg = arg.item()\n",
    "        except:\n",
    "            nista = True\n",
    "        if type(arg) == float:\n",
    "            pr += format(arg, '5.5f') + \"   \"\n",
    "        else:\n",
    "            pr += str(arg) + \"   \"\n",
    "    print(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inace nije manje od 5\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "varijabla = 4\n",
    "varijabla = varijabla + 2\n",
    "varijabla = 10\n",
    "if varijabla < 5:\n",
    "    print(\"nesto\")\n",
    "else:\n",
    "    print(\"inace nije manje od 5\")\n",
    "print(varijabla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polyak(a, b, alfa=0.99):\n",
    "    for namea, parama in a.named_parameters():\n",
    "        for nameb, paramb in b.named_parameters():\n",
    "            if namea == nameb:\n",
    "                paramb.data = paramb.data*alfa + parama.data*(1-alfa)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lin1.weight tensor([[ 0.1197, -3.6151,  2.6557,  1.4156],\n",
      "        [ 0.1485, -3.0528,  5.9003,  1.8968],\n",
      "        [ 0.0934, -2.8544, -4.3781, -1.6724],\n",
      "        [-0.0355, -3.6109, -2.4051, -1.3029],\n",
      "        [-0.1063, -4.3173, -1.0575, -1.5653],\n",
      "        [-0.0297, -0.1277,  0.0252, -0.0081],\n",
      "        [ 0.1278, -3.6504,  3.0260,  1.0528],\n",
      "        [-0.4213, -3.7537, -4.0628, -1.3907]])\n",
      "lin1.bias tensor([-4.6746,  2.4506,  2.1437,  3.0268, -3.4248, -0.3000,  3.2480,  2.4914])\n",
      "lin2.weight tensor([[ 4.3942, -3.1680, -2.3143, -2.3613,  4.0309,  0.0149, -3.1521, -2.3794]])\n",
      "lin2.bias tensor([-1.5159])\n",
      "d\n",
      "lin1.weight tensor([[ 0.1572, -3.6595,  2.5627,  1.4374],\n",
      "        [ 0.1544, -3.0498,  5.8094,  1.8874],\n",
      "        [ 0.0804, -2.8371, -4.2820, -1.6619],\n",
      "        [-0.0405, -3.5885, -2.3373, -1.2875],\n",
      "        [-0.1161, -4.3694, -1.0454, -1.5521],\n",
      "        [-0.0297, -0.1277,  0.0252, -0.0081],\n",
      "        [ 0.1464, -3.6148,  2.9774,  1.0646],\n",
      "        [-0.4397, -3.7344, -3.9813, -1.3731]])\n",
      "lin1.bias tensor([-4.6621,  2.5047,  2.1883,  3.0728, -3.3945, -0.3000,  3.2788,  2.5416])\n",
      "lin2.weight tensor([[ 4.4057, -3.1564, -2.2976, -2.3589,  4.0303,  0.0149, -3.1503, -2.3683]])\n",
      "lin2.bias tensor([-1.5282])\n"
     ]
    }
   ],
   "source": [
    "for n, p in q.named_parameters():\n",
    "    print(n, p.data)\n",
    "    \n",
    "print(\"d\")\n",
    "for n, p in qtarget.named_parameters():\n",
    "    print(n, p.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = polyak(q, qtarget, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lin1.weight tensor([[ 0.1197, -3.6151,  2.6557,  1.4156],\n",
      "        [ 0.1485, -3.0528,  5.9003,  1.8968],\n",
      "        [ 0.0934, -2.8544, -4.3781, -1.6724],\n",
      "        [-0.0355, -3.6109, -2.4051, -1.3029],\n",
      "        [-0.1063, -4.3173, -1.0575, -1.5653],\n",
      "        [-0.0297, -0.1277,  0.0252, -0.0081],\n",
      "        [ 0.1278, -3.6504,  3.0260,  1.0528],\n",
      "        [-0.4213, -3.7537, -4.0628, -1.3907]])\n",
      "lin1.bias tensor([-4.6746,  2.4506,  2.1437,  3.0268, -3.4248, -0.3000,  3.2480,  2.4914])\n",
      "lin2.weight tensor([[ 4.3942, -3.1680, -2.3143, -2.3613,  4.0309,  0.0149, -3.1521, -2.3794]])\n",
      "lin2.bias tensor([-1.5159])\n",
      "d\n",
      "lin1.weight tensor([[ 0.1290, -3.6262,  2.6325,  1.4210],\n",
      "        [ 0.1500, -3.0521,  5.8776,  1.8945],\n",
      "        [ 0.0902, -2.8501, -4.3541, -1.6698],\n",
      "        [-0.0368, -3.6053, -2.3881, -1.2990],\n",
      "        [-0.1087, -4.3303, -1.0545, -1.5620],\n",
      "        [-0.0297, -0.1277,  0.0252, -0.0081],\n",
      "        [ 0.1325, -3.6415,  3.0139,  1.0558],\n",
      "        [-0.4259, -3.7489, -4.0424, -1.3863]])\n",
      "lin1.bias tensor([-4.6715,  2.4642,  2.1549,  3.0383, -3.4172, -0.3000,  3.2557,  2.5039])\n",
      "lin2.weight tensor([[ 4.3971, -3.1651, -2.3102, -2.3607,  4.0307,  0.0149, -3.1517, -2.3766]])\n",
      "lin2.bias tensor([-1.5189])\n",
      "d\n",
      "lin1.weight tensor([[ 0.1290, -3.6262,  2.6325,  1.4210],\n",
      "        [ 0.1500, -3.0521,  5.8776,  1.8945],\n",
      "        [ 0.0902, -2.8501, -4.3541, -1.6698],\n",
      "        [-0.0368, -3.6053, -2.3881, -1.2990],\n",
      "        [-0.1087, -4.3303, -1.0545, -1.5620],\n",
      "        [-0.0297, -0.1277,  0.0252, -0.0081],\n",
      "        [ 0.1325, -3.6415,  3.0139,  1.0558],\n",
      "        [-0.4259, -3.7489, -4.0424, -1.3863]])\n",
      "lin1.bias tensor([-4.6715,  2.4642,  2.1549,  3.0383, -3.4172, -0.3000,  3.2557,  2.5039])\n",
      "lin2.weight tensor([[ 4.3971, -3.1651, -2.3102, -2.3607,  4.0307,  0.0149, -3.1517, -2.3766]])\n",
      "lin2.bias tensor([-1.5189])\n"
     ]
    }
   ],
   "source": [
    "for n, p in q.named_parameters():\n",
    "    print(n, p.data)\n",
    "    \n",
    "print(\"d\")\n",
    "for n, p in qtarget.named_parameters():\n",
    "    print(n, p.data)\n",
    "\n",
    "print(\"d\")\n",
    "for n, p in b.named_parameters():\n",
    "    print(n, p.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
