{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "import myrl \n",
    "from myrl.buffers import ReplayBuffer, PrioritizedReplayBuffer\n",
    "from myrl.visualizer import showit\n",
    "from myrl.utils import ExperimentWriter, get_batch_obs, get_batch_a, Discrete2Continuous\n",
    "from myrl.value_functions import polyak, DQN\n",
    "from myrl.policies import RandomPolicy\n",
    "from myrl.environments import Envs\n",
    "\n",
    "envname = 'LunarLander-v2'\n",
    "envname = 'CartPole-v0'\n",
    "env = gym.make(envname)\n",
    "envs = Envs(envname, 1)\n",
    "\n",
    "\n",
    "wll = ExperimentWriter('tb/' + envname + \" -\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbuff = ReplayBuffer(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Discrete(2) Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (4,), float32)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DQN(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=4, out_features=32, bias=True)\n",
       "    (1): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (2): Linear(in_features=32, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "print(env.action_space, env.observation_space)\n",
    "adim = 2 #env.action_space.shape[0]\n",
    "sdim = env.observation_space.shape[0]\n",
    "dqn1 = DQN([sdim, 32, 32, adim])\n",
    "dqn2 = DQN([sdim, 32, 32, adim])\n",
    "\n",
    "import copy\n",
    "tdqn1 = copy.deepcopy(dqn1)\n",
    "tdqn2 = copy.deepcopy(dqn2)\n",
    "\n",
    "dqn1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(list(dqn1.parameters())+list(dqn2.parameters()), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "400 0.6886881589889526 tensor(32.)\n",
      "410 0.43063944578170776 tensor(32.)\n",
      "420 0.36125636100769043 tensor(32.)\n",
      "430 0.5335972309112549 tensor(32.)\n",
      "440 0.5002211332321167 tensor(32.)\n",
      "450 0.4755089581012726 tensor(32.)\n",
      "460 0.4661303162574768 tensor(32.)\n",
      "470 0.3455895483493805 tensor(32.)\n",
      "480 0.5163539052009583 tensor(32.)\n",
      "490 0.5611607432365417 tensor(32.)\n",
      "500 0.3459252715110779 tensor(32.)\n",
      "510 0.458261638879776 tensor(32.)\n",
      "520 0.4232293963432312 tensor(32.)\n",
      "530 0.6557198762893677 tensor(32.)\n",
      "540 0.45939815044403076 tensor(32.)\n",
      "550 0.6972138285636902 tensor(32.)\n",
      "560 0.8536415696144104 tensor(32.)\n",
      "570 0.7665558457374573 tensor(32.)\n",
      "580 0.3403170108795166 tensor(32.)\n",
      "590 0.49962857365608215 tensor(32.)\n",
      "600 0.6635268926620483 tensor(32.)\n",
      "610 0.14883294701576233 tensor(32.)\n",
      "620 0.5155174732208252 tensor(32.)\n",
      "630 0.6763342618942261 tensor(32.)\n",
      "640 0.5395363569259644 tensor(32.)\n",
      "650 0.4958474636077881 tensor(32.)\n",
      "660 1.1010005474090576 tensor(32.)\n",
      "670 0.975433349609375 tensor(32.)\n",
      "680 0.6248775720596313 tensor(32.)\n",
      "690 0.6424494981765747 tensor(32.)\n",
      "700 0.4604417085647583 tensor(32.)\n",
      "710 0.7473483681678772 tensor(32.)\n",
      "720 0.8487512469291687 tensor(32.)\n",
      "730 0.7775475978851318 tensor(32.)\n",
      "740 0.5138179063796997 tensor(32.)\n",
      "750 0.7181870937347412 tensor(32.)\n",
      "760 0.7336176633834839 tensor(32.)\n",
      "770 0.909821093082428 tensor(32.)\n",
      "780 0.6004974842071533 tensor(32.)\n",
      "790 0.9360955953598022 tensor(32.)\n",
      "800 0.7764793038368225 tensor(32.)\n",
      "810 0.8298361897468567 tensor(32.)\n",
      "820 1.08180570602417 tensor(32.)\n",
      "830 0.6736206412315369 tensor(32.)\n",
      "840 0.44665300846099854 tensor(32.)\n",
      "850 0.5955450534820557 tensor(32.)\n",
      "860 0.6430315971374512 tensor(32.)\n",
      "870 1.0990036725997925 tensor(32.)\n",
      "880 0.33072346448898315 tensor(32.)\n",
      "890 0.6968421936035156 tensor(32.)\n",
      "900 0.46112367510795593 tensor(32.)\n",
      "910 1.4616527557373047 tensor(32.)\n",
      "920 0.9021977782249451 tensor(32.)\n",
      "930 0.9167675375938416 tensor(32.)\n",
      "940 0.379537433385849 tensor(32.)\n",
      "950 0.9667155742645264 tensor(32.)\n",
      "960 0.5612953305244446 tensor(32.)\n",
      "970 0.754459023475647 tensor(32.)\n",
      "980 0.5608545541763306 tensor(32.)\n",
      "990 1.1018049716949463 tensor(32.)\n"
     ]
    }
   ],
   "source": [
    "#wll.new()\n",
    "writer = wll.writer\n",
    "\n",
    "bsize = 32\n",
    "warmup = 400 \n",
    "gamma = 1\n",
    "collector = lambda obs: dqn1.act(obs, epsilon=0.15)\n",
    "shower    = lambda obs: dqn1.act(obs, epsilon=0)\n",
    "random_policy = RandomPolicy(env).act\n",
    "\n",
    "\n",
    "\n",
    "for ep in range(400, 1000):\n",
    "    obs = env.reset()\n",
    "    if ep%1==0:\n",
    "        pi = collector if len(rbuff)>bsize*5 else random_policy\n",
    "        oldobs, _, r, obs, d, _, _, a = envs.rollout(pi)\n",
    "        rbuff.add(oldobs, a, r, obs, d)\n",
    "        writer.add_scalar('dqn/reward', r.sum(), ep)\n",
    "        # writer.add_scalar('a/reward', rss, ep)\n",
    "    # print(r.sum())\n",
    "    if bsize*10 > len(rbuff):\n",
    "        continue\n",
    "\n",
    "    for i in range(15):\n",
    "        oldobs, a, r, obs, done = rbuff.get(bsize)\n",
    "        for opt_step in range(4):\n",
    "            import random\n",
    "            if random.uniform(0, 1) > 0.5:\n",
    "                max_action = dqn1.get_action(obs)\n",
    "                target = dqn2.get_q(obs, max_action)\n",
    "            else:\n",
    "                max_action = dqn2.get_action(obs)\n",
    "                target = dqn1.get_q(obs, max_action)\n",
    "\n",
    "            target = target*gamma*(1-done) + r            \n",
    "            calc1 = dqn1.get_q(oldobs, a)\n",
    "            calc2 = dqn2.get_q(oldobs, a)\n",
    "            l2 = ((target - calc2)**2).mean()\n",
    "            l1 = ((target - calc1)**2).mean()\n",
    "            loss = l1 + l2\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "    writer.add_scalar('a/dqn1', l1.item(), ep)\n",
    "    writer.add_scalar('a/dqn2', l2.item(), ep)\n",
    "    \n",
    "    polyak(dqn1, tdqn1, 1-1/50)\n",
    "    polyak(dqn2, tdqn2, 1-1/50)\n",
    "    \n",
    "    if ep%10==0:\n",
    "        print(ep, loss.item(), r.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}