{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bit41770f51cb494085b126429b02db281f",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "255 / 256"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(3, 1)"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import gym\n",
    "from myrl.environments import Envs\n",
    "from myrl.policies import GaussianPolicy\n",
    "from myrl.value_functions import ValueFunctionMLP, polyak\n",
    "from myrl.visualizer import showit\n",
    "from myrl.utils import ExperimentWriter, check_output, global_gradient_clip \n",
    "from myrl.buffers import ReplayBuffer\n",
    "import torch\n",
    "import copy\n",
    "\n",
    "envname = 'LunarLanderContinuous-v2'\n",
    "envname = 'Pendulum-v0'\n",
    "\n",
    "wll = ExperimentWriter('tb/ppo_pendulum_test_thatworks_')\n",
    "env = gym.make(envname)\n",
    "idim = env.observation_space.shape[0]\n",
    "odim = env.action_space.shape[0]\n",
    "envs = Envs(envname, 256)\n",
    "envs.evenout(200)\n",
    "idim, odim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pi = GaussianPolicy([idim, 64, 64, odim], std_start=0.9, std_min=0.1)\n",
    "vfunc = ValueFunctionMLP([idim, 64, 64, odim])\n",
    "tvfunc = copy.deepcopy(vfunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "bonus = RandomNetworkBonus([idim, 128, 1], [idim, 128, 1], lr=1e-4, opt_steps=1)\n",
    "tvfunc = copy.deepcopy(vfunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(pi.parameters(), lr=3e-4)\n",
    "copt = torch.optim.Adam(vfunc.parameters(), lr=2e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-2c5e395d8218>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0moldobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moldprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmpls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmuold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mbon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbonus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_bonus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mbonus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mujoco-py/myrl/environments.py\u001b[0m in \u001b[0;36mrollout\u001b[0;34m(self, pi, gamma, length, debug)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0ml2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mujoco-py/myrl/environments.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, pi, debug)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0menv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0ml2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mujoco-py/myrl/environments.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, act, sample, debug)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0masq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0masq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mujoco-py/myrl/policies.py\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, o, smpl, debug)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_range\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_range\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mujoco-py/myrl/policies.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlay\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhook_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_hooks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m             \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "wll.new()\n",
    "writer = wll.writer\n",
    "eps = 10000\n",
    "gamma = 1\n",
    "\n",
    "for ep in range(0, eps):\n",
    "    oldobs, a, r, obs, d, oldprobs, smpls, muold, stdold = envs.rollout(pi.act)\n",
    "    # bon = bonus.get_bonus(obs)\n",
    "    # bonus.step(obs)\n",
    "    # r += bon*100\n",
    "    r = envs.discounted_sum(r, gamma)\n",
    "    print(r.shape)\n",
    "    rbuff = ReplayBuffer(nitems=9, max_len=100000)\n",
    "    rbuff.add(oldobs, a, r, obs, d, oldprobs, smpls, muold, stdold)\n",
    "    # print(len(rbuff), \"leni\")\n",
    "\n",
    "    for imini_batch in range(15):\n",
    "        oldobs, a, r, obs, d, oldprobs, smpls, muold, stdold = rbuff.get(len(rbuff)//10)\n",
    "        adv = r - vfunc(oldobs).detach() #+ vfunc(obs).detach()*gamma*(1-d)\n",
    "        adv = ((adv-adv.mean())/(adv.std()+1e-8)).detach()\n",
    "        for optstep in range(4):\n",
    "            _, (newprobs, _, mu, std) = pi.act(oldobs, smpl=smpls)\n",
    "            p = torch.distributions.Normal(muold, stdold)\n",
    "            q = torch.distributions.Normal(mu, std)\n",
    "            kldiv = torch.distributions.kl_divergence(p, q)\n",
    "            if kldiv.mean().item() > 0.03:\n",
    "                # print(\"stopppp\", kldiv.mean().item(), optstep)\n",
    "                break\n",
    "            # print(kldiv)\n",
    "            ratio = torch.exp(newprobs-oldprobs)\n",
    "            e = 0.15\n",
    "            clipped = (ratio != torch.clamp(ratio, 1-e, 1+e)).float().mean().detach().item()\n",
    "            loss = -torch.min(ratio*adv, torch.clamp(ratio, 1-e, 1+e)*adv).mean()\n",
    "            opt.zero_grad()\n",
    "            loss.backward()shooting method: optimize over actions only\n",
    "            global_gradient_clip(pi)\n",
    "            opt.step()\n",
    "        \n",
    "        for optstep in range(4):                    \n",
    "            td = ((r - vfunc(oldobs))**2).mean()\n",
    "            copt.zero_grad()\n",
    "            td.backward()\n",
    "            copt.step()\n",
    "\n",
    "        rsss =  r.mean().item()\n",
    "        polyak(vfunc, tvfunc, 1-1/50)\n",
    "\n",
    "\n",
    "    if ep%4==0:\n",
    "        print(ep, loss.item(), \"r\", r.mean().item()-bon.mean().item()*100, \" td\", td.item(), \"clip\", clipped, \"___\", pi.last_std.mean().item(), bon.mean().item()*100)\n",
    "    if ep%50==0:\n",
    "        print(\"showit=\",showit(env, pi.act, max_steps=650))\n",
    "        env.close()\n",
    "        # print(mu.squeeze(1)[:20])\n",
    "\n",
    "\n",
    "    writer.add_scalar(\"a/loss\", loss.item(), ep)\n",
    "    writer.add_scalar(\"a/td\", td.item(), ep)\n",
    "    writer.add_scalar(\"a/reward\", r.mean(), ep)\n",
    "    writer.add_scalar(\"a/clipped\", clipped, ep)\n",
    "    writer.add_scalar(\"a/lr\", opt.param_groups[0]['lr'], ep)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Using cpu device\n----------------------------------\n| rollout/           |           |\n|    ep_len_mean     | 200       |\n|    ep_rew_mean     | -1.24e+03 |\n| time/              |           |\n|    fps             | 3906      |\n|    iterations      | 1         |\n|    time_elapsed    | 2         |\n|    total_timesteps | 8192      |\n----------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 200         |\n|    ep_rew_mean          | -1.21e+03   |\n| time/                   |             |\n|    fps                  | 1847        |\n|    iterations           | 2           |\n|    time_elapsed         | 8           |\n|    total_timesteps      | 16384       |\n| train/                  |             |\n|    approx_kl            | 0.001112595 |\n|    clip_fraction        | 0           |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.41       |\n|    explained_variance   | -6e+03      |\n|    learning_rate        | 0.0003      |\n|    loss                 | 2.5e+03     |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.000453   |\n|    std                  | 0.99        |\n|    value_loss           | 7.37e+03    |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 200          |\n|    ep_rew_mean          | -1.2e+03     |\n| time/                   |              |\n|    fps                  | 1559         |\n|    iterations           | 3            |\n|    time_elapsed         | 15           |\n|    total_timesteps      | 24576        |\n| train/                  |              |\n|    approx_kl            | 0.0024789865 |\n|    clip_fraction        | 0.0312       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.41        |\n|    explained_variance   | -1.04e+04    |\n|    learning_rate        | 0.0003       |\n|    loss                 | 2.46e+03     |\n|    n_updates            | 20           |\n|    policy_gradient_loss | -0.000808    |\n|    std                  | 0.985        |\n|    value_loss           | 6.28e+03     |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 200         |\n|    ep_rew_mean          | -1.21e+03   |\n| time/                   |             |\n|    fps                  | 1492        |\n|    iterations           | 4           |\n|    time_elapsed         | 21          |\n|    total_timesteps      | 32768       |\n| train/                  |             |\n|    approx_kl            | 0.003141529 |\n|    clip_fraction        | 0.0156      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.4        |\n|    explained_variance   | -1.3e+06    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 2.3e+03     |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.0019     |\n|    std                  | 0.98        |\n|    value_loss           | 5.57e+03    |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 200          |\n|    ep_rew_mean          | -1.23e+03    |\n| time/                   |              |\n|    fps                  | 1448         |\n|    iterations           | 5            |\n|    time_elapsed         | 28           |\n|    total_timesteps      | 40960        |\n| train/                  |              |\n|    approx_kl            | 0.0045195343 |\n|    clip_fraction        | 0.0469       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.39        |\n|    explained_variance   | -1.42e+07    |\n|    learning_rate        | 0.0003       |\n|    loss                 | 2.48e+03     |\n|    n_updates            | 40           |\n|    policy_gradient_loss | -0.00139     |\n|    std                  | 0.969        |\n|    value_loss           | 6.46e+03     |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 200         |\n|    ep_rew_mean          | -1.26e+03   |\n| time/                   |             |\n|    fps                  | 1412        |\n|    iterations           | 6           |\n|    time_elapsed         | 34          |\n|    total_timesteps      | 49152       |\n| train/                  |             |\n|    approx_kl            | 0.004683422 |\n|    clip_fraction        | 0           |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.39       |\n|    explained_variance   | -3.09e+07   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 1.89e+03    |\n|    n_updates            | 50          |\n|    policy_gradient_loss | -0.00168    |\n|    std                  | 0.975       |\n|    value_loss           | 5.22e+03    |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 200         |\n|    ep_rew_mean          | -1.24e+03   |\n| time/                   |             |\n|    fps                  | 1387        |\n|    iterations           | 7           |\n|    time_elapsed         | 41          |\n|    total_timesteps      | 57344       |\n| train/                  |             |\n|    approx_kl            | 0.001922993 |\n|    clip_fraction        | 0.0312      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.4        |\n|    explained_variance   | -1.58e+08   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 2.16e+03    |\n|    n_updates            | 60          |\n|    policy_gradient_loss | -0.0005     |\n|    std                  | 0.975       |\n|    value_loss           | 5.3e+03     |\n-----------------------------------------\n"
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from stable_baselines3.common.cmd_util import make_vec_env\n",
    "\n",
    "# Parallel environments\n",
    "env = make_vec_env(envname, n_envs=4)\n",
    "\n",
    "model = PPO(MlpPolicy, env, verbose=2)\n",
    "model.learn(total_timesteps=50000, log_interval=1, tb_log_name='/home/darijan/mujoco-py/tb/ppo_stable_4')\n",
    "\n",
    "env = gym.make(envname)\n",
    "obs = env.reset()\n",
    "\n",
    "for i in range(200):\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    env.render()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RandomNetworkBonus():\n",
    "    def __init__(self, random_net_arch, estimator_net_arch, lr, opt_steps=2, weight=1):\n",
    "        self.random_net = ValueFunctionMLP(random_net_arch)\n",
    "        self.estimator_net = ValueFunctionMLP(estimator_net_arch)\n",
    "        self.opt = torch.optim.Adam(self.estimator_net.parameters(), lr=lr)\n",
    "        self.opt_steps = opt_steps\n",
    "        self.weight = weight\n",
    "    def step(self, obs):\n",
    "        for i in range(self.opt_steps):\n",
    "            loss = ((self.random_net(obs) + self.estimator_net(obs))**2).mean()\n",
    "            self.opt.zero_grad()\n",
    "            loss.backward()\n",
    "            self.opt.step()\n",
    "    def get_bonus(self, obs):\n",
    "        loss = ((self.random_net(obs) + self.estimator_net(obs))**2).detach()\n",
    "        if loss.shape[0] > 1:\n",
    "            return loss\n",
    "        return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntrinsicCuriosityModule():\n",
    "    def __init__(self, ):\n",
    "        self.inverse_model = pass\n",
    "        self.forward_model = pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "284 /2000"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "182.735506752273"
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "showit(env, pi.act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}