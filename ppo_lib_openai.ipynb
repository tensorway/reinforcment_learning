{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bit41770f51cb494085b126429b02db281f",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(8, 2)"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "import gym\n",
    "from myrl.environments import Envs\n",
    "from myrl.policies import GaussianPolicy\n",
    "from myrl.value_functions import ValueFunctionMLP, polyak\n",
    "from myrl.visualizer import showit\n",
    "from myrl.utils import ExperimentWriter, check_output, global_gradient_clip \n",
    "from myrl.buffers import ReplayBuffer\n",
    "import torch\n",
    "import copy\n",
    "\n",
    "envname = 'LunarLanderContinuous-v2'\n",
    "# envname = 'Pendulum-v0'\n",
    "\n",
    "wll = ExperimentWriter('tb/ppo_lun_curious_')\n",
    "env = gym.make(envname)\n",
    "idim = env.observation_space.shape[0]\n",
    "odim = env.action_space.shape[0]\n",
    "envs = Envs(envname, 4)\n",
    "# envs.evenout(200)\n",
    "idim, odim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pi = GaussianPolicy([idim, 64, 64, odim], std_start=0.9, std_min=0.1)\n",
    "vfunc = ValueFunctionMLP([idim, 64, 64, odim])\n",
    "tvfunc = copy.deepcopy(vfunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bonus = RandomNetworkBonus([idim, 128, 1], [idim, 128, 1], lr=1e-4, opt_steps=1)\n",
    "tvfunc = copy.deepcopy(vfunc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(pi.parameters(), lr=3e-4)\n",
    "copt = torch.optim.Adam(vfunc.parameters(), lr=2e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0 -0.0029380368068814278 r -38.44097754219547  td 3250.54248046875 clip 0.0 ___ 0.720962405204773 0.11002203682437539\nshowit= -174.1745670771495\n4 -0.001292870263569057 r -27.718106530606747  td 2330.606201171875 clip 0.0 ___ 0.7267155051231384 2.882533334195614\n8 -0.0013082309160381556 r -52.77108614798635  td 9683.8623046875 clip 0.0 ___ 0.7256836295127869 0.36927645560353994\n12 -0.0004536219057627022 r -76.2408279273659  td 13141.2587890625 clip 0.0 ___ 0.7238295674324036 0.37869871594011784\n16 -0.0041170730255544186 r -32.46529074013233  td 4120.0478515625 clip 0.0 ___ 0.7229253053665161 1.2391764670610428\n20 -0.0028424065094441175 r -18.98022198677063  td 1.9729820489883423 clip 0.0 ___ 0.7244485020637512 18.671494722366333\n24 -0.008192663080990314 r -35.165094615891576  td 4106.28564453125 clip 0.0 ___ 0.7192338705062866 0.5841810721904039\n28 -0.0007566241547465324 r -71.89846699032933  td 12180.4306640625 clip 0.0 ___ 0.72895348072052 0.2779683331027627\n32 0.0002081262064166367 r -117.03986540995538  td 29372.103515625 clip 0.0 ___ 0.7254743576049805 0.7131671067327261\n36 -0.0003238959761802107 r -38.17256918922067  td 2521.4052734375 clip 0.0 ___ 0.7261672616004944 0.5213812924921513\n40 -0.00046025225310586393 r -54.57619282603264  td 8380.5205078125 clip 0.0 ___ 0.7270787358283997 0.3738574683666229\n44 -0.0005570451612584293 r -55.63402819260955  td 18341.87890625 clip 0.0 ___ 0.739609956741333 0.5123279057443142\n48 -0.00033399774110876024 r -28.124115807935596  td 2099.030029296875 clip 0.0 ___ 0.7437651753425598 0.3984249662607908\nshowit= -171.25640006447094\n52 -0.002344107488170266 r -37.111863997764885  td 3202.2333984375 clip 0.0 ___ 0.7483404278755188 0.3514536889269948\n56 -0.0004883248475380242 r -76.94876422639936  td 9511.7216796875 clip 0.0 ___ 0.7559040784835815 0.24271716829389334\n60 -0.00012492948735598475 r -44.22617318760604  td 4218.4736328125 clip 0.0 ___ 0.750097930431366 0.23793771397322416\n64 -0.0009565638611093163 r -36.79040812142193  td 5213.00146484375 clip 0.0 ___ 0.7763575911521912 0.3133878577500582\n68 -0.001969842705875635 r -43.157241941429675  td 4028.568603515625 clip 0.0 ___ 0.767889678478241 0.386242032982409\n72 -0.0062281908467411995 r -23.484608363360167  td 1754.59814453125 clip 0.0 ___ 0.7751280665397644 1.4575163833796978\n76 -0.006447079591453075 r -30.817657395265996  td 2514.30908203125 clip 0.0 ___ 0.7703754305839539 0.2642573555931449\n80 -0.01634359173476696 r -56.36051516979933  td 4885.81201171875 clip 0.0 ___ 0.8016121983528137 2.3922381922602654\n84 -0.0037765223532915115 r -21.287029781378806  td 1571.50439453125 clip 0.0 ___ 0.7877415418624878 0.3524575615301728\n88 -0.0038069847505539656 r -29.476995079312474  td 2424.7900390625 clip 0.0 ___ 0.7512143850326538 0.07664641598239541\n92 -0.0015671063447371125 r -69.68078666646034  td 8665.6142578125 clip 0.0 ___ 0.767336368560791 0.27088981587439775\n96 -3.5577904782257974e-05 r -15.089936460368335  td 1008.166015625 clip 0.0 ___ 0.7898427248001099 0.38580342661589384\n100 -0.0029091620817780495 r -24.363287560641766  td 1636.524169921875 clip 0.0 ___ 0.7936596274375916 0.6237817928195\nshowit= -116.70030280458016\n104 -0.012738509103655815 r -29.047759287059307  td 2217.14697265625 clip 0.0 ___ 0.7754177451133728 1.52804683893919\n108 -0.0018453557277098298 r -90.13521158974618  td 19559.486328125 clip 0.0 ___ 0.7765852212905884 0.2733646659180522\n112 -0.0006295253988355398 r -34.515759896487  td 1367.5821533203125 clip 0.0 ___ 0.7534633278846741 0.6159643642604351\n116 -0.0007755575934424996 r -2.744850654155016  td 173.4691162109375 clip 0.0 ___ 0.7439127564430237 0.3109944052994251\n120 0.001464810105971992 r -31.125350495800376  td 1891.1964111328125 clip 0.0 ___ 0.7197158336639404 0.256738206371665\n124 -0.007484964560717344 r -29.572655469179153  td 1802.0225830078125 clip 0.0 ___ 0.6836450099945068 3.475857526063919\n128 -0.0016358671709895134 r -45.555814229883254  td 2310.7177734375 clip 0.0 ___ 0.7167300581932068 0.2108320826664567\n132 -0.003591281594708562 r -23.362810536287725  td 601.4388427734375 clip 0.0066225165501236916 ___ 0.7058100700378418 0.14258043374866247\n136 -0.004133974201977253 r -33.29636228829622  td 1787.306396484375 clip 0.0 ___ 0.7090358138084412 0.9999679401516914\n140 -0.0002995017566718161 r -34.51442151516676  td 1872.954345703125 clip 0.0 ___ 0.7708786725997925 0.3329334780573845\n144 -0.0002273522550240159 r -14.105555332731456  td 6148.53662109375 clip 0.0 ___ 0.6911157369613647 0.17892912728711963\n148 -0.0002427629951853305 r -62.24783997097984  td 3492.923095703125 clip 0.0 ___ 0.6919698119163513 0.13385681668296456\n101 /650showit= -210.8594613480751\n152 -0.0010046405950561166 r -30.468466027639806  td 977.7299194335938 clip 0.0 ___ 0.6443579196929932 0.09237693157047033\n156 -0.0017067828448489308 r -36.73068242520094  td 1966.408447265625 clip 0.0 ___ 0.7139471769332886 0.45943837612867355\n160 -0.00426497170701623 r -20.210909381508827  td 1410.946044921875 clip 0.0 ___ 0.6971728801727295 0.484684482216835\n164 -0.0012436701217666268 r -38.857801001518965  td 2392.62646484375 clip 0.0 ___ 0.736534059047699 0.5339446477591991\n168 3.183796798111871e-05 r -35.083229003008455  td 1630.1209716796875 clip 0.0 ___ 0.6442912817001343 0.09631722932681441\n172 8.247618097811937e-05 r -36.20017249556258  td 710.9207763671875 clip 0.0 ___ 0.6297070384025574 0.10715873213484883\n176 -0.001057151355780661 r -34.92043954413384  td 3089.5234375 clip 0.0 ___ 0.6496274471282959 0.16518670599907637\n180 -0.0001261811557924375 r -51.62133748549968  td 5143.939453125 clip 0.0 ___ 0.6864778399467468 0.2838512184098363\n184 -0.0007584759732708335 r -66.06415221747011  td 4609.61279296875 clip 0.0 ___ 0.6924124360084534 0.14592406805604696\n188 -0.002199424896389246 r -24.09483378531877  td 1118.895263671875 clip 0.0 ___ 0.6784133315086365 0.04561083915177733\n192 -0.002718332689255476 r -25.946754936128855  td 2609.447021484375 clip 0.0 ___ 0.6588214635848999 0.6090321578085423\n196 -0.005871984176337719 r -26.931131922639906  td 1243.092529296875 clip 0.0 ___ 0.6538544297218323 0.34115465823560953\n200 -0.0006112434202805161 r -26.17887390544638  td 1467.1171875 clip 0.0 ___ 0.7105079293251038 0.15184296062216163\nshowit= -85.30048983365315\n204 -0.015674976631999016 r -33.25425524963066  td 1660.093017578125 clip 0.0 ___ 0.7294880151748657 0.10758776916190982\n208 -0.0034482909832149744 r -33.738420153036714  td 1980.3009033203125 clip 0.0 ___ 0.7289451956748962 0.10236897505819798\n212 -0.0005392790189944208 r -40.063198251184076  td 2279.84716796875 clip 0.0 ___ 0.7412776350975037 0.14041535323485732\n216 -0.0018396081868559122 r -57.75600128015503  td 2279.1669921875 clip 0.0 ___ 0.7184184193611145 0.11604385217651725\n220 -0.0018644887022674084 r -21.173971440643072  td 3188.991455078125 clip 0.0 ___ 0.7218132615089417 0.14065196737647057\n224 -0.00018291157903149724 r -30.28810185799375  td 836.2369384765625 clip 0.0 ___ 0.7376694083213806 0.13236874947324395\n228 -0.0033197703305631876 r -37.412315311376005  td 866.5989990234375 clip 0.0 ___ 0.7174627780914307 0.1369246863760054\n232 -0.018430175259709358 r -14.603390176780522  td 1416.2960205078125 clip 0.0 ___ 0.7209446430206299 0.3016657428815961\n236 -0.0018846581224352121 r -47.43346860050224  td 2460.4150390625 clip 0.0 ___ 0.7030364274978638 0.0943153107073158\n240 -0.0017451026942580938 r -41.61549921007827  td 1130.5283203125 clip 0.0 ___ 0.6733320355415344 0.066785525996238\n244 -0.0007560710073448718 r -34.967139564454556  td 496.770263671875 clip 0.0 ___ 0.6586574912071228 0.19781049340963364\n248 -0.010097967460751534 r -34.50488642603159  td 785.8272705078125 clip 0.0 ___ 0.6987954378128052 2.4908864870667458\n92 /650showit= -344.91701179141717\n252 -0.00011693209671648219 r -34.0880209999159  td 2262.01904296875 clip 0.0 ___ 0.6706645488739014 0.0915534095838666\n256 -0.0017356049502268434 r -30.047257999889553  td 1499.7669677734375 clip 0.0 ___ 0.6902480125427246 0.09595833253115416\n260 -0.00038267753552645445 r -33.61326573044062  td 2017.24365234375 clip 0.0 ___ 0.7075088620185852 0.11665318161249161\n264 -0.0006983416387811303 r -41.710236424347386  td 1876.0826416015625 clip 0.0 ___ 0.6719756126403809 0.061699742218479514\n268 -0.0027050068601965904 r -20.44736788631417  td 944.5802001953125 clip 0.0 ___ 0.689096212387085 0.0647575652692467\n272 -0.006091891787946224 r -19.141657487489283  td 1406.7066650390625 clip 0.0 ___ 0.6859352588653564 0.2876593032851815\n276 -0.0029467162676155567 r -21.749742060899734  td 917.9666137695312 clip 0.0 ___ 0.6622152328491211 1.2798495590686798\n280 -0.0009374441578984261 r -64.35503108426929  td 13812.1435546875 clip 0.0 ___ 0.6641556024551392 0.8579264394938946\n284 -0.0004144222766626626 r -34.918305662693456  td 2861.043212890625 clip 0.0 ___ 0.6932233572006226 0.057343748630955815\n288 -0.00022596496273763478 r -46.604474788066  td 1967.49462890625 clip 0.0 ___ 0.6640239357948303 0.057088618632405996\n292 -0.002391693415120244 r -21.404053655220196  td 791.4457397460938 clip 0.0 ___ 0.6775144934654236 0.06405922467820346\n296 -0.0015946842031553388 r -7.508325722999871  td 1255.911376953125 clip 0.0 ___ 0.6770657896995544 0.05455699283629656\n300 -0.010207524523139 r -25.671258984599262  td 1367.916748046875 clip 0.0 ___ 0.7707732915878296 0.08468633750453591\nshowit= -368.03476641108006\n304 -0.004091168288141489 r -21.55517859570682  td 945.283935546875 clip 0.0 ___ 0.7001537084579468 0.33009047619998455\n308 -0.010985469445586205 r -23.645017900504172  td 1014.1303100585938 clip 0.0 ___ 0.7250876426696777 0.28750638011842966\n312 -0.009531323798000813 r -33.07029914855957  td 747.8140869140625 clip 0.0 ___ 0.6860899329185486 0.7558345794677734\n316 -0.0008825816912576556 r -30.41315443930216  td 1945.2296142578125 clip 0.0 ___ 0.702059805393219 0.08005507406778634\n320 -0.007579569239169359 r -19.058356557041407  td 1721.5965576171875 clip 0.0 ___ 0.7452994585037231 0.20844200626015663\n324 -0.0013390312669798732 r -30.461946914205328  td 1519.9339599609375 clip 0.0 ___ 0.7159837484359741 0.08263821364380419\n328 -0.01754177175462246 r -29.341823331080377  td 2058.51953125 clip 0.0 ___ 0.6892929673194885 0.3514382755383849\n332 -0.004157933872193098 r -54.667942267260514  td 1716.636474609375 clip 0.0 ___ 0.7126176357269287 0.039436560473404825\n336 -0.00657744612544775 r -39.10466351918876  td 1662.5654296875 clip 0.0 ___ 0.7772749662399292 0.40320935659110546\n340 -0.0028868960216641426 r -30.71555678243749  td 1225.44384765625 clip 0.0 ___ 0.6644501686096191 0.0270287215244025\n344 0.0003389029880054295 r -29.29543545213528  td 2304.696044921875 clip 0.0 ___ 0.7113931775093079 0.08073475328274071\n348 -0.003781804582104087 r -32.140235632890835  td 1060.365966796875 clip 0.0 ___ 0.694779098033905 0.035911292070522904\nshowit= -242.932638707395\n352 -0.008159236051142216 r -20.763197688851506  td 499.5892028808594 clip 0.0 ___ 0.7212940454483032 0.1188628957606852\n356 -0.0009102523326873779 r -45.82774272095412  td 1318.842529296875 clip 0.0 ___ 0.732823371887207 0.11935725342482328\n360 -0.0013570849550887942 r -59.883262197487056  td 5201.05029296875 clip 0.0 ___ 0.7342027425765991 0.10715059470385313\n364 -0.0021378814708441496 r -46.95839383453131  td 3072.560302734375 clip 0.0 ___ 0.7757299542427063 0.11986996978521347\n368 -0.007060034666210413 r -43.52425677143037  td 2969.739990234375 clip 0.0 ___ 0.8422166705131531 0.4528952296823263\n372 0.0003071196551900357 r -42.12002801336348  td 1132.80908203125 clip 0.0 ___ 0.8065580725669861 0.1915039960294962\n376 -0.00401060888543725 r -40.52639552112669  td 1991.312255859375 clip 0.0 ___ 0.8021062016487122 0.05243082996457815\n380 -4.74559492431581e-05 r -108.79631383763626  td 20547.81640625 clip 0.0 ___ 0.7963584065437317 0.12221868382766843\n384 -0.00117377913556993 r -53.82850909954868  td 8886.3115234375 clip 0.0 ___ 0.7703299522399902 0.06321216351352632\n388 -0.0012605651281774044 r -85.05585730448365  td 14895.0986328125 clip 0.0 ___ 0.7751673460006714 0.4367777146399021\n392 -0.00044731193338520825 r -27.85228349082172  td 865.5764770507812 clip 0.0 ___ 0.7643226385116577 0.2703800331801176\n396 -0.002708675805479288 r -30.584980100626126  td 619.237548828125 clip 0.0 ___ 0.800023078918457 0.08539208793081343\n400 3.380505950190127e-05 r -113.10950610111468  td 7534.978515625 clip 0.0 ___ 0.7706738114356995 0.0878691382240504\nshowit= -232.06795398130058\n404 -0.0005211844691075385 r -63.706891254289076  td 3799.039794921875 clip 0.0 ___ 0.7547335624694824 0.06920357118360698\n408 -0.0013338481076061726 r -31.831726447679102  td 939.3978881835938 clip 0.0 ___ 0.781640887260437 0.05056990776211023\n412 -0.0038012079894542694 r -45.564951837295666  td 1605.5208740234375 clip 0.0 ___ 0.7417694926261902 0.04392141127027571\n416 -0.0012882906012237072 r -19.647772382944822  td 646.5042724609375 clip 0.0 ___ 0.7600275278091431 1.1312375776469707\n420 -0.007508943323045969 r -34.5796606305521  td 1464.08447265625 clip 0.0 ___ 0.825447142124176 0.09189817938022316\n424 -0.01182544231414795 r -31.89088697358966  td 2309.48974609375 clip 0.0 ___ 0.8021373152732849 1.0290305130183697\n428 -0.004415561445057392 r -36.269028233364224  td 1793.6270751953125 clip 0.0 ___ 0.8386428952217102 0.15956168062984943\n432 -0.0026618235278874636 r -48.258820720016956  td 4745.4921875 clip 0.0 ___ 0.7923576831817627 2.05461997538805\n436 -0.0002981406287290156 r -47.773199684219435  td 5163.333984375 clip 0.0 ___ 0.7907509207725525 0.08646643836982548\n440 -0.010828733444213867 r -30.19047536328435  td 3099.003662109375 clip 0.0 ___ 0.8333662152290344 0.33315839245915413\n444 -0.0061209662817418575 r -30.345797793241218  td 538.058349609375 clip 0.0 ___ 0.7737637758255005 0.06486632046289742\n448 -0.01594500057399273 r -28.258087884634733  td 735.5374755859375 clip 0.0 ___ 0.7939755320549011 0.14489246532320976\nshowit= -422.5258763801279\n452 -0.001091279904358089 r -22.143294632434845  td 524.02490234375 clip 0.0 ___ 0.758840799331665 0.1543477177619934\n456 -0.0019307432230561972 r -34.435844271909446  td 1812.4537353515625 clip 0.0 ___ 0.857124924659729 0.16665634466335177\n460 -0.011669057421386242 r -28.608783267904073  td 922.3407592773438 clip 0.0 ___ 0.8708202242851257 0.18005325691774487\n464 -0.007896429859101772 r -29.031490973196924  td 2709.38623046875 clip 0.0 ___ 0.8474978804588318 0.21168773528188467\n468 -0.0004573940532281995 r -56.00491508166306  td 4990.853515625 clip 0.0043290043249726295 ___ 0.8069268465042114 0.04302390734665096\n472 -0.0070983413606882095 r -36.23884703578369  td 476.2485656738281 clip 0.0 ___ 0.8179752230644226 0.005479115861817263\n476 -0.004044232424348593 r 0.15150063298642635  td 9103.9951171875 clip 0.008368200622498989 ___ 0.8643895983695984 0.4633179400116205\n480 -0.0006597125320695341 r -39.15995293285232  td 2429.896240234375 clip 0.0 ___ 0.7929161190986633 0.031904989737086\n484 -0.003785042790696025 r -29.851419318001717  td 1371.6622314453125 clip 0.0 ___ 0.8699008822441101 0.11441408423706889\n488 -0.009324302896857262 r -31.27325939340517  td 3052.5615234375 clip 0.020202020183205605 ___ 0.8991029262542725 0.07742427987977862\n492 -0.0035392988938838243 r -30.09045281354338  td 1921.4388427734375 clip 0.0 ___ 0.8603780269622803 0.06164612714201212\n496 -0.0003915699489880353 r -56.93700706004165  td 8476.4423828125 clip 0.002053388161584735 ___ 0.8771532773971558 0.050734629621729255\n500 -0.0014657388674095273 r -51.64543646143284  td 5020.13671875 clip 0.0 ___ 0.8887403607368469 0.04048651026096195\nshowit= -481.0416768020461\n504 -0.009774989448487759 r -26.91705259727314  td 1238.0076904296875 clip 0.0 ___ 0.9106862545013428 0.12127432273700833\n508 -0.0017705995123833418 r -24.684464579680935  td 1641.462890625 clip 0.0 ___ 0.9257662892341614 0.09050667867995799\n512 -0.0025996873155236244 r -24.332723564933985  td 1528.269775390625 clip 0.0 ___ 0.8241577744483948 0.15326113207265735\n516 6.999012839514762e-05 r -5.602931793080643  td 2193.133056640625 clip 0.0 ___ 0.8419637680053711 0.05566769395954907\n520 -0.008014392107725143 r -21.796829080034513  td 813.6030883789062 clip 0.0 ___ 0.8410500288009644 0.021016930986661464\n524 -0.0038317495491355658 r -45.207187592983246  td 3238.754150390625 clip 0.0 ___ 0.7794283032417297 0.313316285610199\n528 -0.0022516788449138403 r -17.562780495733023  td 708.5899658203125 clip 0.0 ___ 0.8114283084869385 0.5353680811822414\n532 -0.003544522449374199 r -43.21484993363265  td 2616.907958984375 clip 0.0 ___ 0.8552193641662598 0.04504249955061823\n536 -0.0066859605722129345 r -72.34582051821053  td 12654.1953125 clip 0.0 ___ 0.8069258332252502 0.20057973451912403\n540 -0.0031746095046401024 r -43.15049171098508  td 3476.201904296875 clip 0.007194244768470526 ___ 0.8197812438011169 0.07885932573117316\n544 -0.0005022072000429034 r 2.4374395981431007  td 2912.118408203125 clip 0.0 ___ 0.7879701852798462 0.16114171594381332\n548 -0.0009229679126292467 r -1.3096766788512468  td 3449.70361328125 clip 0.0 ___ 0.8139588236808777 0.07930067367851734\nshowit= -167.66898104570578\n552 -0.0005429945886135101 r -41.66589292767458  td 2082.825439453125 clip 0.0 ___ 0.7441771030426025 0.01145109417848289\n556 0.00033046898897737265 r -21.978899222798645  td 507.970947265625 clip 0.0 ___ 0.7721641063690186 0.07830832619220018\n560 -0.0003730884927790612 r -18.240489755757153  td 418.9507751464844 clip 0.0 ___ 0.7530585527420044 0.2178724156692624\n564 -0.00011158631241414696 r -17.288541122106835  td 1818.720458984375 clip 0.0 ___ 0.8157967925071716 0.01922540250234306\n568 0.0005418342771008611 r -18.69862383673899  td 509.162109375 clip 0.0 ___ 0.8142467737197876 0.025152385933324695\n572 -0.013537628576159477 r -29.483345557237044  td 839.3295288085938 clip 0.0 ___ 0.8526707887649536 0.053556967759504914\n576 -0.00812710914760828 r -22.7331435889937  td 1081.138916015625 clip 0.0 ___ 0.8430468440055847 0.0659740180708468\n580 0.00012415683886501938 r -25.509087449871004  td 3760.91943359375 clip 0.0 ___ 0.8479114174842834 0.2603329485282302\n584 0.00021800307149533182 r -54.28383466787636  td 10116.8837890625 clip 0.0 ___ 0.8294111490249634 0.33772108145058155\n588 -0.003095192601904273 r -15.282760160975158  td 1081.0072021484375 clip 0.0 ___ 0.8734220266342163 0.16518260817974806\n592 -0.0002925285662058741 r -26.09545329073444  td 2689.940673828125 clip 0.0 ___ 0.8580460548400879 0.11302760103717446\n596 -0.007885522209107876 r -13.504745232872665  td 705.2566528320312 clip 0.0 ___ 0.8456827998161316 0.35973142366856337\n600 -0.01907932385802269 r -25.741166143212467  td 791.4374389648438 clip 0.06666667014360428 ___ 0.8120290637016296 0.17542174318805337\nshowit= -55.61434524612257\n604 -0.0019505225354805589 r -41.99679698981345  td 2081.649658203125 clip 0.0 ___ 0.7898707985877991 0.19424953497946262\n608 -0.0027869443874806166 r -30.454578779172152  td 3599.199951171875 clip 0.0 ___ 0.8446620106697083 0.13572730822488666\n612 -0.001886217505671084 r -17.05656646564603  td 1388.3594970703125 clip 0.0 ___ 0.8815469145774841 0.1775209791958332\n616 0.0001884525700006634 r 1.976621000096202  td 2526.062255859375 clip 0.0 ___ 0.8693926334381104 0.18862453289330006\n620 -0.0019956068135797977 r -23.120323285460472  td 524.3394165039062 clip 0.0 ___ 0.8416435122489929 0.18306933343410492\n624 -0.0008276952430605888 r -27.793228480033576  td 1583.2603759765625 clip 0.0 ___ 0.8145678043365479 0.2712539164349437\n628 -0.005630170460790396 r -26.650749463122338  td 928.4132690429688 clip 0.0 ___ 0.8154904842376709 0.13021304039284587\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-2c5e395d8218>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0moldobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moldprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmpls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmuold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mbon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbonus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_bonus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mbonus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mujoco-py/myrl/environments.py\u001b[0m in \u001b[0;36mrollout\u001b[0;34m(self, pi, gamma, length, debug)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0ml2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mujoco-py/myrl/environments.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, pi, debug)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0menv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0ml2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mujoco-py/myrl/environments.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, act, sample, debug)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mold_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gym/wrappers/time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cannot call env.step() before calling reset()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_episode_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gym/envs/box2d/lunar_lander.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    300\u001b[0m                                            True)\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mFPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlander\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gym/envs/box2d/lunar_lander.py\u001b[0m in \u001b[0;36mBeginContact\u001b[0;34m(self, contact)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mBeginContact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlander\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcontact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixtureA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlander\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcontact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixtureB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame_over\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "wll.new()\n",
    "writer = wll.writer\n",
    "eps = 10000\n",
    "gamma = 1\n",
    "\n",
    "for ep in range(0, eps):\n",
    "    oldobs, a, r, obs, d, oldprobs, smpls, muold, stdold = envs.rollout(pi.act, length=10000)\n",
    "    bon = bonus.get_bonus(obs)\n",
    "    bonus.step(obs)\n",
    "    r += bon*100*0\n",
    "    r = envs.discounted_sum(r, gamma)\n",
    "    rbuff = ReplayBuffer(nitems=9, max_len=100000)\n",
    "    rbuff.add(oldobs, a, r, obs, d, oldprobs, smpls, muold, stdold)\n",
    "    # print(len(rbuff), \"leni\")\n",
    "\n",
    "    for imini_batch in range(1):\n",
    "        oldobs, a, r, obs, d, oldprobs, smpls, muold, stdold = rbuff.get(len(rbuff)//1-1)\n",
    "        adv = r - vfunc(oldobs).detach() #+ vfunc(obs).detach()*gamma*(1-d)\n",
    "        adv = ((adv-adv.mean())/(adv.std()+1e-8)).detach()\n",
    "        for optstep in range(4):\n",
    "            _, (newprobs, _, mu, std) = pi.act(oldobs, smpl=smpls)\n",
    "            p = torch.distributions.Normal(muold, stdold)\n",
    "            q = torch.distributions.Normal(mu, std)\n",
    "            kldiv = torch.distributions.kl_divergence(p, q)\n",
    "            if kldiv.mean().item() > 0.03:\n",
    "                # print(\"stopppp\", kldiv.mean().item(), optstep)\n",
    "                break\n",
    "            # print(kldiv)\n",
    "            ratio = torch.exp(newprobs-oldprobs)\n",
    "            e = 0.15\n",
    "            clipped = (ratio != torch.clamp(ratio, 1-e, 1+e)).float().mean().detach().item()\n",
    "            loss = -torch.min(ratio*adv, torch.clamp(ratio, 1-e, 1+e)*adv).mean()\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            global_gradient_clip(pi)\n",
    "            opt.step()\n",
    "        \n",
    "        for optstep in range(4):                    \n",
    "            td = ((r - vfunc(oldobs))**2).mean()\n",
    "            copt.zero_grad()\n",
    "            td.backward()\n",
    "            copt.step()\n",
    "\n",
    "        rsss =  r.mean().item()\n",
    "        polyak(vfunc, tvfunc, 1-1/50)\n",
    "\n",
    "\n",
    "    if ep%4==0:\n",
    "        print(ep, loss.item(), \"r\", r.mean().item()-bon.mean().item()*100, \" td\", td.item(), \"clip\", clipped, \"___\", pi.last_std.mean().item(), bon.mean().item()*100)\n",
    "    if ep%50==0:\n",
    "        print(\"showit=\",showit(env, pi.act, max_steps=650))\n",
    "        env.close()\n",
    "        # print(mu.squeeze(1)[:20])\n",
    "\n",
    "\n",
    "    writer.add_scalar(\"a/loss\", loss.item(), ep)\n",
    "    writer.add_scalar(\"a/td\", td.item(), ep)\n",
    "    writer.add_scalar(\"a/reward\", r.mean(), ep)\n",
    "    writer.add_scalar(\"a/clipped\", clipped, ep)\n",
    "    writer.add_scalar(\"a/lr\", opt.param_groups[0]['lr'], ep)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "|    clip_range           | 0.2         |\n|    entropy_loss         | -2.75       |\n|    explained_variance   | 0.657       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 20.8        |\n|    n_updates            | 90          |\n|    policy_gradient_loss | -0.00768    |\n|    std                  | 0.959       |\n|    value_loss           | 99.6        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 131         |\n|    ep_rew_mean          | -11.4       |\n| time/                   |             |\n|    fps                  | 924         |\n|    iterations           | 11          |\n|    time_elapsed         | 97          |\n|    total_timesteps      | 90112       |\n| train/                  |             |\n|    approx_kl            | 0.007990321 |\n|    clip_fraction        | 0.0781      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -2.74       |\n|    explained_variance   | 0.794       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 33.2        |\n|    n_updates            | 100         |\n|    policy_gradient_loss | -0.00625    |\n|    std                  | 0.949       |\n|    value_loss           | 87.2        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 155          |\n|    ep_rew_mean          | -9.35        |\n| time/                   |              |\n|    fps                  | 893          |\n|    iterations           | 12           |\n|    time_elapsed         | 109          |\n|    total_timesteps      | 98304        |\n| train/                  |              |\n|    approx_kl            | 0.0057065105 |\n|    clip_fraction        | 0.0469       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -2.69        |\n|    explained_variance   | 0.885        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 51.4         |\n|    n_updates            | 110          |\n|    policy_gradient_loss | -0.0074      |\n|    std                  | 0.919        |\n|    value_loss           | 64.4         |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 167         |\n|    ep_rew_mean          | -3.98       |\n| time/                   |             |\n|    fps                  | 851         |\n|    iterations           | 13          |\n|    time_elapsed         | 125         |\n|    total_timesteps      | 106496      |\n| train/                  |             |\n|    approx_kl            | 0.008238076 |\n|    clip_fraction        | 0.141       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -2.66       |\n|    explained_variance   | 0.904       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 17.7        |\n|    n_updates            | 120         |\n|    policy_gradient_loss | -0.00535    |\n|    std                  | 0.911       |\n|    value_loss           | 72.3        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 203          |\n|    ep_rew_mean          | 3.21         |\n| time/                   |              |\n|    fps                  | 811          |\n|    iterations           | 14           |\n|    time_elapsed         | 141          |\n|    total_timesteps      | 114688       |\n| train/                  |              |\n|    approx_kl            | 0.0054339925 |\n|    clip_fraction        | 0.0312       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -2.63        |\n|    explained_variance   | 0.949        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 13.9         |\n|    n_updates            | 130          |\n|    policy_gradient_loss | -0.00498     |\n|    std                  | 0.892        |\n|    value_loss           | 48.5         |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 248         |\n|    ep_rew_mean          | 6.55        |\n| time/                   |             |\n|    fps                  | 775         |\n|    iterations           | 15          |\n|    time_elapsed         | 158         |\n|    total_timesteps      | 122880      |\n| train/                  |             |\n|    approx_kl            | 0.008507604 |\n|    clip_fraction        | 0.0625      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -2.58       |\n|    explained_variance   | 0.96        |\n|    learning_rate        | 0.0003      |\n|    loss                 | 10.8        |\n|    n_updates            | 140         |\n|    policy_gradient_loss | -0.00386    |\n|    std                  | 0.876       |\n|    value_loss           | 34.3        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 298         |\n|    ep_rew_mean          | 13.3        |\n| time/                   |             |\n|    fps                  | 750         |\n|    iterations           | 16          |\n|    time_elapsed         | 174         |\n|    total_timesteps      | 131072      |\n| train/                  |             |\n|    approx_kl            | 0.005014675 |\n|    clip_fraction        | 0.0469      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -2.57       |\n|    explained_variance   | 0.95        |\n|    learning_rate        | 0.0003      |\n|    loss                 | 4.32        |\n|    n_updates            | 150         |\n|    policy_gradient_loss | -0.00348    |\n|    std                  | 0.878       |\n|    value_loss           | 31.8        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 351          |\n|    ep_rew_mean          | 19.9         |\n| time/                   |              |\n|    fps                  | 724          |\n|    iterations           | 17           |\n|    time_elapsed         | 192          |\n|    total_timesteps      | 139264       |\n| train/                  |              |\n|    approx_kl            | 0.0066878935 |\n|    clip_fraction        | 0.0469       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -2.54        |\n|    explained_variance   | 0.957        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 7.48         |\n|    n_updates            | 160          |\n|    policy_gradient_loss | -0.0044      |\n|    std                  | 0.859        |\n|    value_loss           | 33.7         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 423          |\n|    ep_rew_mean          | 25.4         |\n| time/                   |              |\n|    fps                  | 708          |\n|    iterations           | 18           |\n|    time_elapsed         | 208          |\n|    total_timesteps      | 147456       |\n| train/                  |              |\n|    approx_kl            | 0.0066936393 |\n|    clip_fraction        | 0.0469       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -2.5         |\n|    explained_variance   | 0.965        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 7.06         |\n|    n_updates            | 170          |\n|    policy_gradient_loss | -0.00344     |\n|    std                  | 0.84         |\n|    value_loss           | 16.5         |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 468         |\n|    ep_rew_mean          | 30.1        |\n| time/                   |             |\n|    fps                  | 684         |\n|    iterations           | 19          |\n|    time_elapsed         | 227         |\n|    total_timesteps      | 155648      |\n| train/                  |             |\n|    approx_kl            | 0.004667945 |\n|    clip_fraction        | 0.0312      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -2.46       |\n|    explained_variance   | 0.952       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 6.83        |\n|    n_updates            | 180         |\n|    policy_gradient_loss | -0.00168    |\n|    std                  | 0.822       |\n|    value_loss           | 27.1        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 538         |\n|    ep_rew_mean          | 38.2        |\n| time/                   |             |\n|    fps                  | 672         |\n|    iterations           | 20          |\n|    time_elapsed         | 243         |\n|    total_timesteps      | 163840      |\n| train/                  |             |\n|    approx_kl            | 0.008453377 |\n|    clip_fraction        | 0.0312      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -2.42       |\n|    explained_variance   | 0.956       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 52.1        |\n|    n_updates            | 190         |\n|    policy_gradient_loss | -0.00497    |\n|    std                  | 0.812       |\n|    value_loss           | 22.4        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 591          |\n|    ep_rew_mean          | 47.1         |\n| time/                   |              |\n|    fps                  | 653          |\n|    iterations           | 21           |\n|    time_elapsed         | 263          |\n|    total_timesteps      | 172032       |\n| train/                  |              |\n|    approx_kl            | 0.0073578656 |\n|    clip_fraction        | 0.141        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -2.4         |\n|    explained_variance   | 0.968        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 2.77         |\n|    n_updates            | 200          |\n|    policy_gradient_loss | -0.00336     |\n|    std                  | 0.797        |\n|    value_loss           | 14           |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 606         |\n|    ep_rew_mean          | 53.1        |\n| time/                   |             |\n|    fps                  | 640         |\n|    iterations           | 22          |\n|    time_elapsed         | 281         |\n|    total_timesteps      | 180224      |\n| train/                  |             |\n|    approx_kl            | 0.006562841 |\n|    clip_fraction        | 0.0469      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -2.36       |\n|    explained_variance   | 0.972       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 24.5        |\n|    n_updates            | 210         |\n|    policy_gradient_loss | -0.00314    |\n|    std                  | 0.787       |\n|    value_loss           | 12.4        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 664         |\n|    ep_rew_mean          | 64.1        |\n| time/                   |             |\n|    fps                  | 631         |\n|    iterations           | 23          |\n|    time_elapsed         | 298         |\n|    total_timesteps      | 188416      |\n| train/                  |             |\n|    approx_kl            | 0.011880569 |\n|    clip_fraction        | 0.156       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -2.32       |\n|    explained_variance   | 0.954       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 2.96        |\n|    n_updates            | 220         |\n|    policy_gradient_loss | -0.00504    |\n|    std                  | 0.766       |\n|    value_loss           | 19.8        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 720         |\n|    ep_rew_mean          | 75.5        |\n| time/                   |             |\n|    fps                  | 627         |\n|    iterations           | 24          |\n|    time_elapsed         | 313         |\n|    total_timesteps      | 196608      |\n| train/                  |             |\n|    approx_kl            | 0.007806804 |\n|    clip_fraction        | 0.0781      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -2.28       |\n|    explained_variance   | 0.959       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 2.01        |\n|    n_updates            | 230         |\n|    policy_gradient_loss | -0.00367    |\n|    std                  | 0.754       |\n|    value_loss           | 12.8        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 769         |\n|    ep_rew_mean          | 83.2        |\n| time/                   |             |\n|    fps                  | 616         |\n|    iterations           | 25          |\n|    time_elapsed         | 332         |\n|    total_timesteps      | 204800      |\n| train/                  |             |\n|    approx_kl            | 0.007872471 |\n|    clip_fraction        | 0.0625      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -2.23       |\n|    explained_variance   | 0.943       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 5.66        |\n|    n_updates            | 240         |\n|    policy_gradient_loss | -0.00149    |\n|    std                  | 0.731       |\n|    value_loss           | 18.3        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 805         |\n|    ep_rew_mean          | 90.4        |\n| time/                   |             |\n|    fps                  | 609         |\n|    iterations           | 26          |\n|    time_elapsed         | 349         |\n|    total_timesteps      | 212992      |\n| train/                  |             |\n|    approx_kl            | 0.010350861 |\n|    clip_fraction        | 0.0938      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -2.18       |\n|    explained_variance   | 0.96        |\n|    learning_rate        | 0.0003      |\n|    loss                 | 2.4         |\n|    n_updates            | 250         |\n|    policy_gradient_loss | -0.00245    |\n|    std                  | 0.715       |\n|    value_loss           | 11.1        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 829         |\n|    ep_rew_mean          | 96.8        |\n| time/                   |             |\n|    fps                  | 603         |\n|    iterations           | 27          |\n|    time_elapsed         | 366         |\n|    total_timesteps      | 221184      |\n| train/                  |             |\n|    approx_kl            | 0.005309643 |\n|    clip_fraction        | 0.0312      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -2.15       |\n|    explained_variance   | 0.972       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 2.18        |\n|    n_updates            | 260         |\n|    policy_gradient_loss | -0.00177    |\n|    std                  | 0.711       |\n|    value_loss           | 9.69        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 837         |\n|    ep_rew_mean          | 99.8        |\n| time/                   |             |\n|    fps                  | 594         |\n|    iterations           | 28          |\n|    time_elapsed         | 385         |\n|    total_timesteps      | 229376      |\n| train/                  |             |\n|    approx_kl            | 0.008547903 |\n|    clip_fraction        | 0.0312      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -2.13       |\n|    explained_variance   | 0.967       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 1.56        |\n|    n_updates            | 270         |\n|    policy_gradient_loss | -0.00273    |\n|    std                  | 0.698       |\n|    value_loss           | 10.3        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 852          |\n|    ep_rew_mean          | 106          |\n| time/                   |              |\n|    fps                  | 586          |\n|    iterations           | 29           |\n|    time_elapsed         | 404          |\n|    total_timesteps      | 237568       |\n| train/                  |              |\n|    approx_kl            | 0.0048717707 |\n|    clip_fraction        | 0.0938       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -2.08        |\n|    explained_variance   | 0.972        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 2.16         |\n|    n_updates            | 280          |\n|    policy_gradient_loss | -0.00147     |\n|    std                  | 0.679        |\n|    value_loss           | 5.49         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 869          |\n|    ep_rew_mean          | 113          |\n| time/                   |              |\n|    fps                  | 579          |\n|    iterations           | 30           |\n|    time_elapsed         | 424          |\n|    total_timesteps      | 245760       |\n| train/                  |              |\n|    approx_kl            | 0.0069757923 |\n|    clip_fraction        | 0.141        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -2.04        |\n|    explained_variance   | 0.966        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 2.2          |\n|    n_updates            | 290          |\n|    policy_gradient_loss | -0.00153     |\n|    std                  | 0.668        |\n|    value_loss           | 8.75         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 878          |\n|    ep_rew_mean          | 115          |\n| time/                   |              |\n|    fps                  | 575          |\n|    iterations           | 31           |\n|    time_elapsed         | 441          |\n|    total_timesteps      | 253952       |\n| train/                  |              |\n|    approx_kl            | 0.0053810133 |\n|    clip_fraction        | 0.0469       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -2.01        |\n|    explained_variance   | 0.932        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 2.98         |\n|    n_updates            | 300          |\n|    policy_gradient_loss | -0.00088     |\n|    std                  | 0.663        |\n|    value_loss           | 18.7         |\n------------------------------------------\n"
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from stable_baselines3.common.cmd_util import make_vec_env\n",
    "\n",
    "# Parallel environments\n",
    "env = make_vec_env(envname, n_envs=4)\n",
    "\n",
    "model = PPO(MlpPolicy, env, verbose=2)\n",
    "model.learn(total_timesteps=250000, log_interval=1, tb_log_name='/home/darijan/mujoco-py/tb/ppo_stable_4')\n",
    "\n",
    "env = gym.make(envname)\n",
    "obs = env.reset()\n",
    "\n",
    "for i in range(200):\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    env.render()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RandomNetworkBonus():\n",
    "    def __init__(self, random_net_arch, estimator_net_arch, lr, opt_steps=2, weight=1):\n",
    "        self.random_net = ValueFunctionMLP(random_net_arch)\n",
    "        self.estimator_net = ValueFunctionMLP(estimator_net_arch)\n",
    "        self.opt = torch.optim.Adam(self.estimator_net.parameters(), lr=lr)\n",
    "        self.opt_steps = opt_steps\n",
    "        self.weight = weight\n",
    "    def step(self, obs):\n",
    "        for i in range(self.opt_steps):\n",
    "            loss = ((self.random_net(obs) + self.estimator_net(obs))**2).mean()\n",
    "            self.opt.zero_grad()\n",
    "            loss.backward()\n",
    "            self.opt.step()\n",
    "    def get_bonus(self, obs):\n",
    "        loss = ((self.random_net(obs) + self.estimator_net(obs))**2).detach()\n",
    "        if loss.shape[0] > 1:\n",
    "            return loss\n",
    "        return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntrinsicCuriosityModule():\n",
    "    def __init__(self, ):\n",
    "        self.inverse_model = pass\n",
    "        self.forward_model = pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "284 /2000"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "182.735506752273"
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "showit(env, pi.act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "999"
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "rsum = 0\n",
    "for i in range(1000):\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    env.render()\n",
    "    import time\n",
    "    time.sleep(0.01)\n",
    "    rsum += rewards\n",
    "    print(i, end='\\r')\n",
    "    if dones:\n",
    "        break\n",
    "        print(\"gotovo\")\n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "103.13485146332415"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "rsum"
   ]
  }
 ]
}